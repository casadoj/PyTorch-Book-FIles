{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fqnx2CntI_fo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Setup device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FashionMNIST\n",
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = Path('../data/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "if  not (path / 'FashionMNIST').exists():\n",
        "    print('hola')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Transformations applied on each image\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert images to tensor\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize the images\n",
        "])\n",
        "\n",
        "# Load the dataset\n",
        "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=1000, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the CNN model\n",
        "class FashionCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FashionCNN, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=3, padding=1),  # Input: 1 x 28 x 28, Output: 64 x 28 x 28\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))  # Output: 64 x 14 x 14\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3),  # Output: 64 x 12 x 12\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))  # Output: 64 x 6 x 6\n",
        "\n",
        "        self.fc1 = nn.Linear(64 * 6 * 6, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)  # 10 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.view(out.size(0), -1)  # Flatten the output\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "of337T5Jfeja"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 28, 28]             640\n",
            "              ReLU-2           [-1, 64, 28, 28]               0\n",
            "         MaxPool2d-3           [-1, 64, 14, 14]               0\n",
            "            Conv2d-4           [-1, 64, 12, 12]          36,928\n",
            "              ReLU-5           [-1, 64, 12, 12]               0\n",
            "         MaxPool2d-6             [-1, 64, 6, 6]               0\n",
            "            Linear-7                  [-1, 128]         295,040\n",
            "            Linear-8                   [-1, 10]           1,290\n",
            "================================================================\n",
            "Total params: 333,898\n",
            "Trainable params: 333,898\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.02\n",
            "Params size (MB): 1.27\n",
            "Estimated Total Size (MB): 2.30\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "model = FashionCNN().to(device)  # Assuming your model is already defined and moved to the device\n",
        "summary(model, input_size=(1, 28, 28))  # (Channels, Height, Width)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 -- Loss: 0.480955\n",
            "Train Epoch: 2 -- Loss: 0.379081\n",
            "Train Epoch: 3 -- Loss: 0.290524\n",
            "Train Epoch: 4 -- Loss: 0.340867\n",
            "Train Epoch: 5 -- Loss: 0.279709\n",
            "Train Epoch: 6 -- Loss: 0.264307\n",
            "Train Epoch: 7 -- Loss: 0.260853\n",
            "Train Epoch: 8 -- Loss: 0.215272\n",
            "Train Epoch: 9 -- Loss: 0.203518\n",
            "Train Epoch: 10 -- Loss: 0.195016\n",
            "Train Epoch: 11 -- Loss: 0.217275\n",
            "Train Epoch: 12 -- Loss: 0.202714\n",
            "Train Epoch: 13 -- Loss: 0.187355\n",
            "Train Epoch: 14 -- Loss: 0.179235\n",
            "Train Epoch: 15 -- Loss: 0.175244\n",
            "Train Epoch: 16 -- Loss: 0.179273\n",
            "Train Epoch: 17 -- Loss: 0.187090\n",
            "Train Epoch: 18 -- Loss: 0.197918\n",
            "Train Epoch: 19 -- Loss: 0.137742\n",
            "Train Epoch: 20 -- Loss: 0.151495\n",
            "Train Epoch: 21 -- Loss: 0.141840\n",
            "Train Epoch: 22 -- Loss: 0.164637\n",
            "Train Epoch: 23 -- Loss: 0.181047\n",
            "Train Epoch: 24 -- Loss: 0.142565\n",
            "Train Epoch: 25 -- Loss: 0.108934\n",
            "Train Epoch: 26 -- Loss: 0.121558\n",
            "Train Epoch: 27 -- Loss: 0.130847\n",
            "Train Epoch: 28 -- Loss: 0.116375\n",
            "Train Epoch: 29 -- Loss: 0.113763\n",
            "Train Epoch: 30 -- Loss: 0.112371\n",
            "Train Epoch: 31 -- Loss: 0.128766\n",
            "Train Epoch: 32 -- Loss: 0.096305\n",
            "Train Epoch: 33 -- Loss: 0.090075\n",
            "Train Epoch: 34 -- Loss: 0.123304\n",
            "Train Epoch: 35 -- Loss: 0.118582\n",
            "Train Epoch: 36 -- Loss: 0.109695\n",
            "Train Epoch: 37 -- Loss: 0.096963\n",
            "Train Epoch: 38 -- Loss: 0.081912\n",
            "Train Epoch: 39 -- Loss: 0.081861\n",
            "Train Epoch: 40 -- Loss: 0.070141\n",
            "Train Epoch: 41 -- Loss: 0.070432\n",
            "Train Epoch: 42 -- Loss: 0.068907\n",
            "Train Epoch: 43 -- Loss: 0.051815\n",
            "Train Epoch: 44 -- Loss: 0.069735\n",
            "Train Epoch: 45 -- Loss: 0.069172\n",
            "Train Epoch: 46 -- Loss: 0.054919\n",
            "Train Epoch: 47 -- Loss: 0.046835\n",
            "Train Epoch: 48 -- Loss: 0.047080\n",
            "Train Epoch: 49 -- Loss: 0.063819\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the model, loss function, and optimizer\n",
        "model = FashionCNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Function to train the model\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f'Train Epoch: {epoch} -- Loss: {loss.item():.6f}')\n",
        "\n",
        "# Training the model\n",
        "for epoch in range(1, 50):  # Train for 50 epochs\n",
        "    train(epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 91.59%\n"
          ]
        }
      ],
      "source": [
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuDPs_3tiy6O"
      },
      "source": [
        "# Horses or Humans\n",
        "\n",
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Nys-coaNiyWz"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "# training set\n",
        "url = \"https://storage.googleapis.com/learning-datasets/horse-or-human.zip\"\n",
        "file_name = \"horse-or-human.zip\"\n",
        "training_dir = 'horse-or-human/training/'\n",
        "urllib.request.urlretrieve(url, file_name)\n",
        "\n",
        "zip_ref = zipfile.ZipFile(file_name, 'r')\n",
        "zip_ref.extractall(training_dir)\n",
        "zip_ref.close()\n",
        "\n",
        "# validation set\n",
        "url = \"https://storage.googleapis.com/learning-datasets/validation-horse-or-human.zip\"\n",
        "file_name = \"validation-horse-or-human.zip\"\n",
        "validation_dir = 'horse-or-human/validation/'\n",
        "urllib.request.urlretrieve(url, file_name)\n",
        "\n",
        "zip_ref = zipfile.ZipFile(file_name, 'r')\n",
        "zip_ref.extractall(validation_dir)\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `DataLoader`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Gq1cRZ4xir0j"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define transformations\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((150,150)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.RandomAffine(\n",
        "        degrees=0,  # No rotation\n",
        "        translate=(0.2, 0.2),  # Translate up to 20% vertically and horizontally\n",
        "        scale=(0.8, 1.2),  # Zoom in or out by 20%\n",
        "        shear=20,  # Shear by up to 20 degrees\n",
        "    ),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "])\n",
        "\n",
        "# Transforms for the validation data\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(150),\n",
        "    transforms.CenterCrop(150),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# Load the datasets\n",
        "train_dataset = datasets.ImageFolder(root=training_dir, transform=train_transform)\n",
        "val_dataset = datasets.ImageFolder(root=validation_dir, transform=val_transform)\n",
        "\n",
        "# Data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "vjb6kkGDjnD9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class HorsesHumansCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HorsesHumansCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 18 * 18, 512)\n",
        "        self.drop = nn.Dropout(0.25)\n",
        "        self.fc2 = nn.Linear(512, 1)  # Only 1 output neuron for binary classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 64 * 18 * 18)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)\n",
        "        x = torch.sigmoid(x)  # Use sigmoid to output probabilities\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 16, 150, 150]             448\n",
            "         MaxPool2d-2           [-1, 16, 75, 75]               0\n",
            "            Conv2d-3           [-1, 32, 75, 75]           4,640\n",
            "         MaxPool2d-4           [-1, 32, 37, 37]               0\n",
            "            Conv2d-5           [-1, 64, 37, 37]          18,496\n",
            "         MaxPool2d-6           [-1, 64, 18, 18]               0\n",
            "            Linear-7                  [-1, 512]      10,617,344\n",
            "           Dropout-8                  [-1, 512]               0\n",
            "            Linear-9                    [-1, 1]             513\n",
            "================================================================\n",
            "Total params: 10,641,441\n",
            "Trainable params: 10,641,441\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.26\n",
            "Forward/backward pass size (MB): 5.98\n",
            "Params size (MB): 40.59\n",
            "Estimated Total Size (MB): 46.83\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# instantiate the model\n",
        "model = HorsesHumansCNN().to(device)\n",
        "summary(model, input_size=(3, 150, 150))  # (Channels, Height, Width)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "-dEb0t61jrji"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "def train_model(num_epochs):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device).float()  # Convert labels to float\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images).view(-1)  # Flatten outputs to match label shape\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}')\n",
        "\n",
        "        # Evaluate on training set\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for images, labels in train_loader:\n",
        "                images, labels = images.to(device), labels.to(device).float()\n",
        "                outputs = model(images).view(-1)\n",
        "                predicted = outputs > 0.5  # Threshold predictions\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "            print(f'Training Set Accuracy: {100 * correct / total}%')\n",
        "\n",
        "        # Evaluate on validation set\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device).float()\n",
        "                outputs = model(images).view(-1)\n",
        "                predicted = outputs > 0.5  # Threshold predictions\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "            print(f'Validation Set Accuracy: {100 * correct / total}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.6193670251152732\n",
            "Training Set Accuracy: 75.26777020447906%\n",
            "Validation Set Accuracy: 46.484375%\n",
            "Epoch 2, Loss: 0.4475600204684518\n",
            "Training Set Accuracy: 80.81791626095423%\n",
            "Validation Set Accuracy: 52.734375%\n",
            "Epoch 3, Loss: 0.34609963270750915\n",
            "Training Set Accuracy: 85.97857838364168%\n",
            "Validation Set Accuracy: 80.859375%\n",
            "Epoch 4, Loss: 0.2705128515760104\n",
            "Training Set Accuracy: 88.60759493670886%\n",
            "Validation Set Accuracy: 60.15625%\n",
            "Epoch 5, Loss: 0.2848006807493441\n",
            "Training Set Accuracy: 86.56280428432328%\n",
            "Validation Set Accuracy: 67.96875%\n",
            "Epoch 6, Loss: 0.18927325184146562\n",
            "Training Set Accuracy: 93.4761441090555%\n",
            "Validation Set Accuracy: 60.546875%\n",
            "Epoch 7, Loss: 0.175696986868526\n",
            "Training Set Accuracy: 93.7682570593963%\n",
            "Validation Set Accuracy: 60.15625%\n",
            "Epoch 8, Loss: 0.18096410424561438\n",
            "Training Set Accuracy: 94.0603700097371%\n",
            "Validation Set Accuracy: 57.421875%\n",
            "Epoch 9, Loss: 0.1891976407531536\n",
            "Training Set Accuracy: 96.10516066212269%\n",
            "Validation Set Accuracy: 60.9375%\n",
            "Epoch 10, Loss: 0.13521568379788237\n",
            "Training Set Accuracy: 95.61830574488802%\n",
            "Validation Set Accuracy: 64.0625%\n",
            "Epoch 11, Loss: 0.09926189722098185\n",
            "Training Set Accuracy: 95.13145082765335%\n",
            "Validation Set Accuracy: 61.71875%\n",
            "Epoch 12, Loss: 0.09730686638222048\n",
            "Training Set Accuracy: 97.56572541382668%\n",
            "Validation Set Accuracy: 58.203125%\n",
            "Epoch 13, Loss: 0.11826175614965684\n",
            "Training Set Accuracy: 85.97857838364168%\n",
            "Validation Set Accuracy: 67.578125%\n",
            "Epoch 14, Loss: 0.3890083355434013\n",
            "Training Set Accuracy: 94.3524829600779%\n",
            "Validation Set Accuracy: 53.515625%\n",
            "Epoch 15, Loss: 0.140065415451924\n",
            "Training Set Accuracy: 95.5209347614411%\n",
            "Validation Set Accuracy: 54.6875%\n"
          ]
        }
      ],
      "source": [
        "# train for 15 epochs\n",
        "train_model(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "oLPYYyY2kwzX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9999e-01,\n",
            "        9.3058e-01, 1.0000e+00, 3.0574e-04, 1.0000e+00, 1.6046e-02, 1.0000e+00,\n",
            "        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 6.3237e-06,\n",
            "        9.9981e-01, 1.0000e+00, 1.0000e+00, 9.9999e-01, 7.8751e-01, 1.0000e+00,\n",
            "        1.1637e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 7.3181e-01,\n",
            "        9.9940e-01, 1.0000e+00], device='cuda:0')\n",
            "tensor([1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
            "        0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([9.8918e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
            "        2.9353e-09, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 2.1095e-03,\n",
            "        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 2.3674e-07, 7.1404e-04,\n",
            "        1.0000e+00, 9.9519e-01, 1.0000e+00, 8.8512e-01, 1.0000e+00, 1.0000e+00,\n",
            "        1.0000e+00, 6.0471e-04, 1.0000e+00, 1.4796e-01, 1.0000e+00, 9.2466e-01,\n",
            "        1.0000e+00, 1.0000e+00], device='cuda:0')\n",
            "tensor([1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
            "        1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([1.0000e+00, 2.3071e-09, 4.7213e-04, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
            "        1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9975e-01, 9.9881e-01, 1.0000e+00,\n",
            "        9.1313e-08, 3.3111e-05, 3.8978e-01, 1.0000e+00, 9.8284e-01, 1.0000e+00,\n",
            "        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 2.6117e-11, 3.4130e-01,\n",
            "        9.9362e-01, 1.0000e+00, 1.0000e+00, 1.3128e-06, 9.0775e-06, 2.0205e-01,\n",
            "        9.9922e-01, 1.0000e+00], device='cuda:0')\n",
            "tensor([1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
            "        1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([1.0000e+00, 5.8453e-01, 9.7994e-04, 1.0000e+00, 3.4369e-01, 9.8855e-01,\n",
            "        1.0000e+00, 7.3862e-01, 1.0000e+00, 9.9990e-01, 1.0000e+00, 1.0000e+00,\n",
            "        1.5515e-09, 1.0000e+00, 1.0000e+00, 1.0000e+00, 7.5567e-02, 3.9894e-05,\n",
            "        9.2826e-01, 4.1777e-02, 4.7291e-07, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
            "        1.0000e+00, 1.0000e+00, 9.7824e-01, 5.5368e-09, 1.0000e+00, 8.2284e-01,\n",
            "        5.6311e-01, 1.0000e+00], device='cuda:0')\n",
            "tensor([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.,\n",
            "        0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([8.2354e-12, 1.0000e+00, 2.1621e-04, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
            "        8.3846e-01, 3.1397e-02, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9097e-01,\n",
            "        9.9991e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 8.4324e-09, 1.0000e+00,\n",
            "        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0504e-02, 1.0000e+00, 1.0000e+00,\n",
            "        1.0000e+00, 5.1351e-03, 1.0000e+00, 1.0000e+00, 1.0000e+00, 6.2942e-01,\n",
            "        1.0000e+00, 1.8855e-07], device='cuda:0')\n",
            "tensor([0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
            "        0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "tensor([7.9165e-01, 3.2121e-08, 4.0892e-10, 1.0000e+00, 9.9923e-01, 1.0000e+00,\n",
            "        9.9900e-01, 1.0000e+00, 3.4055e-13, 1.0000e+00, 1.0000e+00, 3.2247e-02,\n",
            "        1.0000e+00, 3.1971e-12, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
            "        2.9261e-05, 4.2019e-10, 1.0000e+00, 1.3049e-04, 1.0000e+00, 1.0000e+00,\n",
            "        6.6678e-01, 1.0000e+00, 1.0000e+00, 5.4278e-01, 1.0000e+00, 1.0000e+00,\n",
            "        1.0000e+00, 1.0000e+00], device='cuda:0')\n",
            "tensor([0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
            "        0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.],\n",
            "       device='cuda:0')\n",
            "tensor([1.0000e+00, 3.5745e-02, 1.0000e+00, 3.8526e-01, 1.0000e+00, 1.0000e+00,\n",
            "        1.0503e-03, 9.3640e-02, 1.0000e+00, 1.0000e+00, 9.9950e-01, 9.9607e-01,\n",
            "        1.0000e+00, 1.0000e+00, 9.9999e-01, 2.7348e-05, 1.0000e+00, 1.7018e-01,\n",
            "        1.0000e+00, 2.1932e-07, 8.1058e-01, 9.9450e-01, 1.0000e+00, 2.2168e-04,\n",
            "        9.9996e-01, 1.3380e-09, 1.0000e+00, 8.5577e-02, 1.2066e-12, 1.0000e+00,\n",
            "        2.2693e-01, 3.3374e-02], device='cuda:0')\n",
            "tensor([1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
            "        1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "       device='cuda:0')\n",
            "tensor([1.0000e+00, 1.0000e+00, 9.0702e-08, 1.0000e+00, 1.0000e+00, 1.6299e-08,\n",
            "        4.5527e-04, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 4.7112e-01,\n",
            "        1.0000e+00, 1.0000e+00, 9.9998e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
            "        1.6186e-04, 9.9998e-01, 1.4161e-16, 1.0000e+00, 2.1513e-03, 4.9608e-03,\n",
            "        1.0000e+00, 3.7781e-01, 1.0000e+00, 9.9735e-01, 1.0000e+00, 1.6564e-03,\n",
            "        1.0000e+00, 8.4046e-02], device='cuda:0')\n",
            "tensor([1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0.],\n",
            "       device='cuda:0')\n",
            "Validation Accuracy: 76.171875%\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device).float()\n",
        "        outputs = model(images).view(-1)\n",
        "        predicted = outputs > 0.5  # Threshold predictions\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        print(outputs)\n",
        "        print(labels)\n",
        "    print(f'Validation Accuracy: {100 * correct / total}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Deploy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "XhssauRyh7dw"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((150, 150)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "def load_image(image_path, transform):\n",
        "    # Load image\n",
        "    image = Image.open(image_path).convert('RGB')  # Convert to RGB just in case it's not\n",
        "    # Apply transformations\n",
        "    image = transform(image)\n",
        "    # Add batch dimension, as the model expects batches\n",
        "    image = image.unsqueeze(0)\n",
        "    return image\n",
        "\n",
        "# Prediction function\n",
        "def predict(image_path, model, device, transform):\n",
        "    model.eval()\n",
        "    image = load_image(image_path, transform)\n",
        "    image = image.to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "        prediction = output > 0.5\n",
        "        class_name = \"Human\" if prediction.item() == 1 else \"Horse\"\n",
        "        print(image_path)\n",
        "        print(f\"The image is predicted to be a {class_name}.\")\n",
        "        print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "horse-or-human/deploy/horse-1330690_640.jpg\n",
            "The image is predicted to be a Horse.\n",
            "tensor([[6.7261e-08]], device='cuda:0')\n",
            "horse-or-human/deploy/portrait-7942151_640.jpg\n",
            "The image is predicted to be a Horse.\n",
            "tensor([[0.0174]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "deploy_dir = Path('./horse-or-human/deploy/')\n",
        "for file in deploy_dir.glob('*.jpg'):\n",
        "    predict(file, model, device, transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# for img in uploaded.keys():\n",
        "#   predict(img, model, device, transform)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cNhqsQfvYO-"
      },
      "source": [
        "# Transfer Learning\n",
        "\n",
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gi0SrZQ9vw2X"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "url = \"https://storage.googleapis.com/learning-datasets/horse-or-human.zip\"\n",
        "file_name = \"horse-or-human.zip\"\n",
        "training_dir = 'horse-or-human/training/'\n",
        "urllib.request.urlretrieve(url, file_name)\n",
        "\n",
        "zip_ref = zipfile.ZipFile(file_name, 'r')\n",
        "zip_ref.extractall(training_dir)\n",
        "zip_ref.close()\n",
        "\n",
        "url = \"https://storage.googleapis.com/learning-datasets/validation-horse-or-human.zip\"\n",
        "file_name = \"validation-horse-or-human.zip\"\n",
        "validation_dir = 'horse-or-human/validation/'\n",
        "urllib.request.urlretrieve(url, file_name)\n",
        "\n",
        "zip_ref = zipfile.ZipFile(file_name, 'r')\n",
        "zip_ref.extractall(validation_dir)\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "SigEpA17559g"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/casadoj/miniconda3/envs/torch/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/home/casadoj/miniconda3/envs/torch/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /home/casadoj/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n",
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " : Inception3\n",
            "Conv2d_1a_3x3 : BasicConv2d\n",
            "Conv2d_1a_3x3.conv : Conv2d\n",
            "Conv2d_1a_3x3.bn : BatchNorm2d\n",
            "Conv2d_2a_3x3 : BasicConv2d\n",
            "Conv2d_2a_3x3.conv : Conv2d\n",
            "Conv2d_2a_3x3.bn : BatchNorm2d\n",
            "Conv2d_2b_3x3 : BasicConv2d\n",
            "Conv2d_2b_3x3.conv : Conv2d\n",
            "Conv2d_2b_3x3.bn : BatchNorm2d\n",
            "maxpool1 : MaxPool2d\n",
            "Conv2d_3b_1x1 : BasicConv2d\n",
            "Conv2d_3b_1x1.conv : Conv2d\n",
            "Conv2d_3b_1x1.bn : BatchNorm2d\n",
            "Conv2d_4a_3x3 : BasicConv2d\n",
            "Conv2d_4a_3x3.conv : Conv2d\n",
            "Conv2d_4a_3x3.bn : BatchNorm2d\n",
            "maxpool2 : MaxPool2d\n",
            "Mixed_5b : InceptionA\n",
            "Mixed_5b.branch1x1 : BasicConv2d\n",
            "Mixed_5b.branch1x1.conv : Conv2d\n",
            "Mixed_5b.branch1x1.bn : BatchNorm2d\n",
            "Mixed_5b.branch5x5_1 : BasicConv2d\n",
            "Mixed_5b.branch5x5_1.conv : Conv2d\n",
            "Mixed_5b.branch5x5_1.bn : BatchNorm2d\n",
            "Mixed_5b.branch5x5_2 : BasicConv2d\n",
            "Mixed_5b.branch5x5_2.conv : Conv2d\n",
            "Mixed_5b.branch5x5_2.bn : BatchNorm2d\n",
            "Mixed_5b.branch3x3dbl_1 : BasicConv2d\n",
            "Mixed_5b.branch3x3dbl_1.conv : Conv2d\n",
            "Mixed_5b.branch3x3dbl_1.bn : BatchNorm2d\n",
            "Mixed_5b.branch3x3dbl_2 : BasicConv2d\n",
            "Mixed_5b.branch3x3dbl_2.conv : Conv2d\n",
            "Mixed_5b.branch3x3dbl_2.bn : BatchNorm2d\n",
            "Mixed_5b.branch3x3dbl_3 : BasicConv2d\n",
            "Mixed_5b.branch3x3dbl_3.conv : Conv2d\n",
            "Mixed_5b.branch3x3dbl_3.bn : BatchNorm2d\n",
            "Mixed_5b.branch_pool : BasicConv2d\n",
            "Mixed_5b.branch_pool.conv : Conv2d\n",
            "Mixed_5b.branch_pool.bn : BatchNorm2d\n",
            "Mixed_5c : InceptionA\n",
            "Mixed_5c.branch1x1 : BasicConv2d\n",
            "Mixed_5c.branch1x1.conv : Conv2d\n",
            "Mixed_5c.branch1x1.bn : BatchNorm2d\n",
            "Mixed_5c.branch5x5_1 : BasicConv2d\n",
            "Mixed_5c.branch5x5_1.conv : Conv2d\n",
            "Mixed_5c.branch5x5_1.bn : BatchNorm2d\n",
            "Mixed_5c.branch5x5_2 : BasicConv2d\n",
            "Mixed_5c.branch5x5_2.conv : Conv2d\n",
            "Mixed_5c.branch5x5_2.bn : BatchNorm2d\n",
            "Mixed_5c.branch3x3dbl_1 : BasicConv2d\n",
            "Mixed_5c.branch3x3dbl_1.conv : Conv2d\n",
            "Mixed_5c.branch3x3dbl_1.bn : BatchNorm2d\n",
            "Mixed_5c.branch3x3dbl_2 : BasicConv2d\n",
            "Mixed_5c.branch3x3dbl_2.conv : Conv2d\n",
            "Mixed_5c.branch3x3dbl_2.bn : BatchNorm2d\n",
            "Mixed_5c.branch3x3dbl_3 : BasicConv2d\n",
            "Mixed_5c.branch3x3dbl_3.conv : Conv2d\n",
            "Mixed_5c.branch3x3dbl_3.bn : BatchNorm2d\n",
            "Mixed_5c.branch_pool : BasicConv2d\n",
            "Mixed_5c.branch_pool.conv : Conv2d\n",
            "Mixed_5c.branch_pool.bn : BatchNorm2d\n",
            "Mixed_5d : InceptionA\n",
            "Mixed_5d.branch1x1 : BasicConv2d\n",
            "Mixed_5d.branch1x1.conv : Conv2d\n",
            "Mixed_5d.branch1x1.bn : BatchNorm2d\n",
            "Mixed_5d.branch5x5_1 : BasicConv2d\n",
            "Mixed_5d.branch5x5_1.conv : Conv2d\n",
            "Mixed_5d.branch5x5_1.bn : BatchNorm2d\n",
            "Mixed_5d.branch5x5_2 : BasicConv2d\n",
            "Mixed_5d.branch5x5_2.conv : Conv2d\n",
            "Mixed_5d.branch5x5_2.bn : BatchNorm2d\n",
            "Mixed_5d.branch3x3dbl_1 : BasicConv2d\n",
            "Mixed_5d.branch3x3dbl_1.conv : Conv2d\n",
            "Mixed_5d.branch3x3dbl_1.bn : BatchNorm2d\n",
            "Mixed_5d.branch3x3dbl_2 : BasicConv2d\n",
            "Mixed_5d.branch3x3dbl_2.conv : Conv2d\n",
            "Mixed_5d.branch3x3dbl_2.bn : BatchNorm2d\n",
            "Mixed_5d.branch3x3dbl_3 : BasicConv2d\n",
            "Mixed_5d.branch3x3dbl_3.conv : Conv2d\n",
            "Mixed_5d.branch3x3dbl_3.bn : BatchNorm2d\n",
            "Mixed_5d.branch_pool : BasicConv2d\n",
            "Mixed_5d.branch_pool.conv : Conv2d\n",
            "Mixed_5d.branch_pool.bn : BatchNorm2d\n",
            "Mixed_6a : InceptionB\n",
            "Mixed_6a.branch3x3 : BasicConv2d\n",
            "Mixed_6a.branch3x3.conv : Conv2d\n",
            "Mixed_6a.branch3x3.bn : BatchNorm2d\n",
            "Mixed_6a.branch3x3dbl_1 : BasicConv2d\n",
            "Mixed_6a.branch3x3dbl_1.conv : Conv2d\n",
            "Mixed_6a.branch3x3dbl_1.bn : BatchNorm2d\n",
            "Mixed_6a.branch3x3dbl_2 : BasicConv2d\n",
            "Mixed_6a.branch3x3dbl_2.conv : Conv2d\n",
            "Mixed_6a.branch3x3dbl_2.bn : BatchNorm2d\n",
            "Mixed_6a.branch3x3dbl_3 : BasicConv2d\n",
            "Mixed_6a.branch3x3dbl_3.conv : Conv2d\n",
            "Mixed_6a.branch3x3dbl_3.bn : BatchNorm2d\n",
            "Mixed_6b : InceptionC\n",
            "Mixed_6b.branch1x1 : BasicConv2d\n",
            "Mixed_6b.branch1x1.conv : Conv2d\n",
            "Mixed_6b.branch1x1.bn : BatchNorm2d\n",
            "Mixed_6b.branch7x7_1 : BasicConv2d\n",
            "Mixed_6b.branch7x7_1.conv : Conv2d\n",
            "Mixed_6b.branch7x7_1.bn : BatchNorm2d\n",
            "Mixed_6b.branch7x7_2 : BasicConv2d\n",
            "Mixed_6b.branch7x7_2.conv : Conv2d\n",
            "Mixed_6b.branch7x7_2.bn : BatchNorm2d\n",
            "Mixed_6b.branch7x7_3 : BasicConv2d\n",
            "Mixed_6b.branch7x7_3.conv : Conv2d\n",
            "Mixed_6b.branch7x7_3.bn : BatchNorm2d\n",
            "Mixed_6b.branch7x7dbl_1 : BasicConv2d\n",
            "Mixed_6b.branch7x7dbl_1.conv : Conv2d\n",
            "Mixed_6b.branch7x7dbl_1.bn : BatchNorm2d\n",
            "Mixed_6b.branch7x7dbl_2 : BasicConv2d\n",
            "Mixed_6b.branch7x7dbl_2.conv : Conv2d\n",
            "Mixed_6b.branch7x7dbl_2.bn : BatchNorm2d\n",
            "Mixed_6b.branch7x7dbl_3 : BasicConv2d\n",
            "Mixed_6b.branch7x7dbl_3.conv : Conv2d\n",
            "Mixed_6b.branch7x7dbl_3.bn : BatchNorm2d\n",
            "Mixed_6b.branch7x7dbl_4 : BasicConv2d\n",
            "Mixed_6b.branch7x7dbl_4.conv : Conv2d\n",
            "Mixed_6b.branch7x7dbl_4.bn : BatchNorm2d\n",
            "Mixed_6b.branch7x7dbl_5 : BasicConv2d\n",
            "Mixed_6b.branch7x7dbl_5.conv : Conv2d\n",
            "Mixed_6b.branch7x7dbl_5.bn : BatchNorm2d\n",
            "Mixed_6b.branch_pool : BasicConv2d\n",
            "Mixed_6b.branch_pool.conv : Conv2d\n",
            "Mixed_6b.branch_pool.bn : BatchNorm2d\n",
            "Mixed_6c : InceptionC\n",
            "Mixed_6c.branch1x1 : BasicConv2d\n",
            "Mixed_6c.branch1x1.conv : Conv2d\n",
            "Mixed_6c.branch1x1.bn : BatchNorm2d\n",
            "Mixed_6c.branch7x7_1 : BasicConv2d\n",
            "Mixed_6c.branch7x7_1.conv : Conv2d\n",
            "Mixed_6c.branch7x7_1.bn : BatchNorm2d\n",
            "Mixed_6c.branch7x7_2 : BasicConv2d\n",
            "Mixed_6c.branch7x7_2.conv : Conv2d\n",
            "Mixed_6c.branch7x7_2.bn : BatchNorm2d\n",
            "Mixed_6c.branch7x7_3 : BasicConv2d\n",
            "Mixed_6c.branch7x7_3.conv : Conv2d\n",
            "Mixed_6c.branch7x7_3.bn : BatchNorm2d\n",
            "Mixed_6c.branch7x7dbl_1 : BasicConv2d\n",
            "Mixed_6c.branch7x7dbl_1.conv : Conv2d\n",
            "Mixed_6c.branch7x7dbl_1.bn : BatchNorm2d\n",
            "Mixed_6c.branch7x7dbl_2 : BasicConv2d\n",
            "Mixed_6c.branch7x7dbl_2.conv : Conv2d\n",
            "Mixed_6c.branch7x7dbl_2.bn : BatchNorm2d\n",
            "Mixed_6c.branch7x7dbl_3 : BasicConv2d\n",
            "Mixed_6c.branch7x7dbl_3.conv : Conv2d\n",
            "Mixed_6c.branch7x7dbl_3.bn : BatchNorm2d\n",
            "Mixed_6c.branch7x7dbl_4 : BasicConv2d\n",
            "Mixed_6c.branch7x7dbl_4.conv : Conv2d\n",
            "Mixed_6c.branch7x7dbl_4.bn : BatchNorm2d\n",
            "Mixed_6c.branch7x7dbl_5 : BasicConv2d\n",
            "Mixed_6c.branch7x7dbl_5.conv : Conv2d\n",
            "Mixed_6c.branch7x7dbl_5.bn : BatchNorm2d\n",
            "Mixed_6c.branch_pool : BasicConv2d\n",
            "Mixed_6c.branch_pool.conv : Conv2d\n",
            "Mixed_6c.branch_pool.bn : BatchNorm2d\n",
            "Mixed_6d : InceptionC\n",
            "Mixed_6d.branch1x1 : BasicConv2d\n",
            "Mixed_6d.branch1x1.conv : Conv2d\n",
            "Mixed_6d.branch1x1.bn : BatchNorm2d\n",
            "Mixed_6d.branch7x7_1 : BasicConv2d\n",
            "Mixed_6d.branch7x7_1.conv : Conv2d\n",
            "Mixed_6d.branch7x7_1.bn : BatchNorm2d\n",
            "Mixed_6d.branch7x7_2 : BasicConv2d\n",
            "Mixed_6d.branch7x7_2.conv : Conv2d\n",
            "Mixed_6d.branch7x7_2.bn : BatchNorm2d\n",
            "Mixed_6d.branch7x7_3 : BasicConv2d\n",
            "Mixed_6d.branch7x7_3.conv : Conv2d\n",
            "Mixed_6d.branch7x7_3.bn : BatchNorm2d\n",
            "Mixed_6d.branch7x7dbl_1 : BasicConv2d\n",
            "Mixed_6d.branch7x7dbl_1.conv : Conv2d\n",
            "Mixed_6d.branch7x7dbl_1.bn : BatchNorm2d\n",
            "Mixed_6d.branch7x7dbl_2 : BasicConv2d\n",
            "Mixed_6d.branch7x7dbl_2.conv : Conv2d\n",
            "Mixed_6d.branch7x7dbl_2.bn : BatchNorm2d\n",
            "Mixed_6d.branch7x7dbl_3 : BasicConv2d\n",
            "Mixed_6d.branch7x7dbl_3.conv : Conv2d\n",
            "Mixed_6d.branch7x7dbl_3.bn : BatchNorm2d\n",
            "Mixed_6d.branch7x7dbl_4 : BasicConv2d\n",
            "Mixed_6d.branch7x7dbl_4.conv : Conv2d\n",
            "Mixed_6d.branch7x7dbl_4.bn : BatchNorm2d\n",
            "Mixed_6d.branch7x7dbl_5 : BasicConv2d\n",
            "Mixed_6d.branch7x7dbl_5.conv : Conv2d\n",
            "Mixed_6d.branch7x7dbl_5.bn : BatchNorm2d\n",
            "Mixed_6d.branch_pool : BasicConv2d\n",
            "Mixed_6d.branch_pool.conv : Conv2d\n",
            "Mixed_6d.branch_pool.bn : BatchNorm2d\n",
            "Mixed_6e : InceptionC\n",
            "Mixed_6e.branch1x1 : BasicConv2d\n",
            "Mixed_6e.branch1x1.conv : Conv2d\n",
            "Mixed_6e.branch1x1.bn : BatchNorm2d\n",
            "Mixed_6e.branch7x7_1 : BasicConv2d\n",
            "Mixed_6e.branch7x7_1.conv : Conv2d\n",
            "Mixed_6e.branch7x7_1.bn : BatchNorm2d\n",
            "Mixed_6e.branch7x7_2 : BasicConv2d\n",
            "Mixed_6e.branch7x7_2.conv : Conv2d\n",
            "Mixed_6e.branch7x7_2.bn : BatchNorm2d\n",
            "Mixed_6e.branch7x7_3 : BasicConv2d\n",
            "Mixed_6e.branch7x7_3.conv : Conv2d\n",
            "Mixed_6e.branch7x7_3.bn : BatchNorm2d\n",
            "Mixed_6e.branch7x7dbl_1 : BasicConv2d\n",
            "Mixed_6e.branch7x7dbl_1.conv : Conv2d\n",
            "Mixed_6e.branch7x7dbl_1.bn : BatchNorm2d\n",
            "Mixed_6e.branch7x7dbl_2 : BasicConv2d\n",
            "Mixed_6e.branch7x7dbl_2.conv : Conv2d\n",
            "Mixed_6e.branch7x7dbl_2.bn : BatchNorm2d\n",
            "Mixed_6e.branch7x7dbl_3 : BasicConv2d\n",
            "Mixed_6e.branch7x7dbl_3.conv : Conv2d\n",
            "Mixed_6e.branch7x7dbl_3.bn : BatchNorm2d\n",
            "Mixed_6e.branch7x7dbl_4 : BasicConv2d\n",
            "Mixed_6e.branch7x7dbl_4.conv : Conv2d\n",
            "Mixed_6e.branch7x7dbl_4.bn : BatchNorm2d\n",
            "Mixed_6e.branch7x7dbl_5 : BasicConv2d\n",
            "Mixed_6e.branch7x7dbl_5.conv : Conv2d\n",
            "Mixed_6e.branch7x7dbl_5.bn : BatchNorm2d\n",
            "Mixed_6e.branch_pool : BasicConv2d\n",
            "Mixed_6e.branch_pool.conv : Conv2d\n",
            "Mixed_6e.branch_pool.bn : BatchNorm2d\n",
            "AuxLogits : InceptionAux\n",
            "AuxLogits.conv0 : BasicConv2d\n",
            "AuxLogits.conv0.conv : Conv2d\n",
            "AuxLogits.conv0.bn : BatchNorm2d\n",
            "AuxLogits.conv1 : BasicConv2d\n",
            "AuxLogits.conv1.conv : Conv2d\n",
            "AuxLogits.conv1.bn : BatchNorm2d\n",
            "AuxLogits.fc : Linear\n",
            "Mixed_7a : InceptionD\n",
            "Mixed_7a.branch3x3_1 : BasicConv2d\n",
            "Mixed_7a.branch3x3_1.conv : Conv2d\n",
            "Mixed_7a.branch3x3_1.bn : BatchNorm2d\n",
            "Mixed_7a.branch3x3_2 : BasicConv2d\n",
            "Mixed_7a.branch3x3_2.conv : Conv2d\n",
            "Mixed_7a.branch3x3_2.bn : BatchNorm2d\n",
            "Mixed_7a.branch7x7x3_1 : BasicConv2d\n",
            "Mixed_7a.branch7x7x3_1.conv : Conv2d\n",
            "Mixed_7a.branch7x7x3_1.bn : BatchNorm2d\n",
            "Mixed_7a.branch7x7x3_2 : BasicConv2d\n",
            "Mixed_7a.branch7x7x3_2.conv : Conv2d\n",
            "Mixed_7a.branch7x7x3_2.bn : BatchNorm2d\n",
            "Mixed_7a.branch7x7x3_3 : BasicConv2d\n",
            "Mixed_7a.branch7x7x3_3.conv : Conv2d\n",
            "Mixed_7a.branch7x7x3_3.bn : BatchNorm2d\n",
            "Mixed_7a.branch7x7x3_4 : BasicConv2d\n",
            "Mixed_7a.branch7x7x3_4.conv : Conv2d\n",
            "Mixed_7a.branch7x7x3_4.bn : BatchNorm2d\n",
            "Mixed_7b : InceptionE\n",
            "Mixed_7b.branch1x1 : BasicConv2d\n",
            "Mixed_7b.branch1x1.conv : Conv2d\n",
            "Mixed_7b.branch1x1.bn : BatchNorm2d\n",
            "Mixed_7b.branch3x3_1 : BasicConv2d\n",
            "Mixed_7b.branch3x3_1.conv : Conv2d\n",
            "Mixed_7b.branch3x3_1.bn : BatchNorm2d\n",
            "Mixed_7b.branch3x3_2a : BasicConv2d\n",
            "Mixed_7b.branch3x3_2a.conv : Conv2d\n",
            "Mixed_7b.branch3x3_2a.bn : BatchNorm2d\n",
            "Mixed_7b.branch3x3_2b : BasicConv2d\n",
            "Mixed_7b.branch3x3_2b.conv : Conv2d\n",
            "Mixed_7b.branch3x3_2b.bn : BatchNorm2d\n",
            "Mixed_7b.branch3x3dbl_1 : BasicConv2d\n",
            "Mixed_7b.branch3x3dbl_1.conv : Conv2d\n",
            "Mixed_7b.branch3x3dbl_1.bn : BatchNorm2d\n",
            "Mixed_7b.branch3x3dbl_2 : BasicConv2d\n",
            "Mixed_7b.branch3x3dbl_2.conv : Conv2d\n",
            "Mixed_7b.branch3x3dbl_2.bn : BatchNorm2d\n",
            "Mixed_7b.branch3x3dbl_3a : BasicConv2d\n",
            "Mixed_7b.branch3x3dbl_3a.conv : Conv2d\n",
            "Mixed_7b.branch3x3dbl_3a.bn : BatchNorm2d\n",
            "Mixed_7b.branch3x3dbl_3b : BasicConv2d\n",
            "Mixed_7b.branch3x3dbl_3b.conv : Conv2d\n",
            "Mixed_7b.branch3x3dbl_3b.bn : BatchNorm2d\n",
            "Mixed_7b.branch_pool : BasicConv2d\n",
            "Mixed_7b.branch_pool.conv : Conv2d\n",
            "Mixed_7b.branch_pool.bn : BatchNorm2d\n",
            "Mixed_7c : InceptionE\n",
            "Mixed_7c.branch1x1 : BasicConv2d\n",
            "Mixed_7c.branch1x1.conv : Conv2d\n",
            "Mixed_7c.branch1x1.bn : BatchNorm2d\n",
            "Mixed_7c.branch3x3_1 : BasicConv2d\n",
            "Mixed_7c.branch3x3_1.conv : Conv2d\n",
            "Mixed_7c.branch3x3_1.bn : BatchNorm2d\n",
            "Mixed_7c.branch3x3_2a : BasicConv2d\n",
            "Mixed_7c.branch3x3_2a.conv : Conv2d\n",
            "Mixed_7c.branch3x3_2a.bn : BatchNorm2d\n",
            "Mixed_7c.branch3x3_2b : BasicConv2d\n",
            "Mixed_7c.branch3x3_2b.conv : Conv2d\n",
            "Mixed_7c.branch3x3_2b.bn : BatchNorm2d\n",
            "Mixed_7c.branch3x3dbl_1 : BasicConv2d\n",
            "Mixed_7c.branch3x3dbl_1.conv : Conv2d\n",
            "Mixed_7c.branch3x3dbl_1.bn : BatchNorm2d\n",
            "Mixed_7c.branch3x3dbl_2 : BasicConv2d\n",
            "Mixed_7c.branch3x3dbl_2.conv : Conv2d\n",
            "Mixed_7c.branch3x3dbl_2.bn : BatchNorm2d\n",
            "Mixed_7c.branch3x3dbl_3a : BasicConv2d\n",
            "Mixed_7c.branch3x3dbl_3a.conv : Conv2d\n",
            "Mixed_7c.branch3x3dbl_3a.bn : BatchNorm2d\n",
            "Mixed_7c.branch3x3dbl_3b : BasicConv2d\n",
            "Mixed_7c.branch3x3dbl_3b.conv : Conv2d\n",
            "Mixed_7c.branch3x3dbl_3b.bn : BatchNorm2d\n",
            "Mixed_7c.branch_pool : BasicConv2d\n",
            "Mixed_7c.branch_pool.conv : Conv2d\n",
            "Mixed_7c.branch_pool.bn : BatchNorm2d\n",
            "avgpool : AdaptiveAvgPool2d\n",
            "dropout : Dropout\n",
            "fc : Linear\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 149, 149]             864\n",
            "       BatchNorm2d-2         [-1, 32, 149, 149]              64\n",
            "       BasicConv2d-3         [-1, 32, 149, 149]               0\n",
            "            Conv2d-4         [-1, 32, 147, 147]           9,216\n",
            "       BatchNorm2d-5         [-1, 32, 147, 147]              64\n",
            "       BasicConv2d-6         [-1, 32, 147, 147]               0\n",
            "            Conv2d-7         [-1, 64, 147, 147]          18,432\n",
            "       BatchNorm2d-8         [-1, 64, 147, 147]             128\n",
            "       BasicConv2d-9         [-1, 64, 147, 147]               0\n",
            "        MaxPool2d-10           [-1, 64, 73, 73]               0\n",
            "           Conv2d-11           [-1, 80, 73, 73]           5,120\n",
            "      BatchNorm2d-12           [-1, 80, 73, 73]             160\n",
            "      BasicConv2d-13           [-1, 80, 73, 73]               0\n",
            "           Conv2d-14          [-1, 192, 71, 71]         138,240\n",
            "      BatchNorm2d-15          [-1, 192, 71, 71]             384\n",
            "      BasicConv2d-16          [-1, 192, 71, 71]               0\n",
            "        MaxPool2d-17          [-1, 192, 35, 35]               0\n",
            "           Conv2d-18           [-1, 64, 35, 35]          12,288\n",
            "      BatchNorm2d-19           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-20           [-1, 64, 35, 35]               0\n",
            "           Conv2d-21           [-1, 48, 35, 35]           9,216\n",
            "      BatchNorm2d-22           [-1, 48, 35, 35]              96\n",
            "      BasicConv2d-23           [-1, 48, 35, 35]               0\n",
            "           Conv2d-24           [-1, 64, 35, 35]          76,800\n",
            "      BatchNorm2d-25           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-26           [-1, 64, 35, 35]               0\n",
            "           Conv2d-27           [-1, 64, 35, 35]          12,288\n",
            "      BatchNorm2d-28           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-29           [-1, 64, 35, 35]               0\n",
            "           Conv2d-30           [-1, 96, 35, 35]          55,296\n",
            "      BatchNorm2d-31           [-1, 96, 35, 35]             192\n",
            "      BasicConv2d-32           [-1, 96, 35, 35]               0\n",
            "           Conv2d-33           [-1, 96, 35, 35]          82,944\n",
            "      BatchNorm2d-34           [-1, 96, 35, 35]             192\n",
            "      BasicConv2d-35           [-1, 96, 35, 35]               0\n",
            "           Conv2d-36           [-1, 32, 35, 35]           6,144\n",
            "      BatchNorm2d-37           [-1, 32, 35, 35]              64\n",
            "      BasicConv2d-38           [-1, 32, 35, 35]               0\n",
            "       InceptionA-39          [-1, 256, 35, 35]               0\n",
            "           Conv2d-40           [-1, 64, 35, 35]          16,384\n",
            "      BatchNorm2d-41           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-42           [-1, 64, 35, 35]               0\n",
            "           Conv2d-43           [-1, 48, 35, 35]          12,288\n",
            "      BatchNorm2d-44           [-1, 48, 35, 35]              96\n",
            "      BasicConv2d-45           [-1, 48, 35, 35]               0\n",
            "           Conv2d-46           [-1, 64, 35, 35]          76,800\n",
            "      BatchNorm2d-47           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-48           [-1, 64, 35, 35]               0\n",
            "           Conv2d-49           [-1, 64, 35, 35]          16,384\n",
            "      BatchNorm2d-50           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-51           [-1, 64, 35, 35]               0\n",
            "           Conv2d-52           [-1, 96, 35, 35]          55,296\n",
            "      BatchNorm2d-53           [-1, 96, 35, 35]             192\n",
            "      BasicConv2d-54           [-1, 96, 35, 35]               0\n",
            "           Conv2d-55           [-1, 96, 35, 35]          82,944\n",
            "      BatchNorm2d-56           [-1, 96, 35, 35]             192\n",
            "      BasicConv2d-57           [-1, 96, 35, 35]               0\n",
            "           Conv2d-58           [-1, 64, 35, 35]          16,384\n",
            "      BatchNorm2d-59           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-60           [-1, 64, 35, 35]               0\n",
            "       InceptionA-61          [-1, 288, 35, 35]               0\n",
            "           Conv2d-62           [-1, 64, 35, 35]          18,432\n",
            "      BatchNorm2d-63           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-64           [-1, 64, 35, 35]               0\n",
            "           Conv2d-65           [-1, 48, 35, 35]          13,824\n",
            "      BatchNorm2d-66           [-1, 48, 35, 35]              96\n",
            "      BasicConv2d-67           [-1, 48, 35, 35]               0\n",
            "           Conv2d-68           [-1, 64, 35, 35]          76,800\n",
            "      BatchNorm2d-69           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-70           [-1, 64, 35, 35]               0\n",
            "           Conv2d-71           [-1, 64, 35, 35]          18,432\n",
            "      BatchNorm2d-72           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-73           [-1, 64, 35, 35]               0\n",
            "           Conv2d-74           [-1, 96, 35, 35]          55,296\n",
            "      BatchNorm2d-75           [-1, 96, 35, 35]             192\n",
            "      BasicConv2d-76           [-1, 96, 35, 35]               0\n",
            "           Conv2d-77           [-1, 96, 35, 35]          82,944\n",
            "      BatchNorm2d-78           [-1, 96, 35, 35]             192\n",
            "      BasicConv2d-79           [-1, 96, 35, 35]               0\n",
            "           Conv2d-80           [-1, 64, 35, 35]          18,432\n",
            "      BatchNorm2d-81           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-82           [-1, 64, 35, 35]               0\n",
            "       InceptionA-83          [-1, 288, 35, 35]               0\n",
            "           Conv2d-84          [-1, 384, 17, 17]         995,328\n",
            "      BatchNorm2d-85          [-1, 384, 17, 17]             768\n",
            "      BasicConv2d-86          [-1, 384, 17, 17]               0\n",
            "           Conv2d-87           [-1, 64, 35, 35]          18,432\n",
            "      BatchNorm2d-88           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-89           [-1, 64, 35, 35]               0\n",
            "           Conv2d-90           [-1, 96, 35, 35]          55,296\n",
            "      BatchNorm2d-91           [-1, 96, 35, 35]             192\n",
            "      BasicConv2d-92           [-1, 96, 35, 35]               0\n",
            "           Conv2d-93           [-1, 96, 17, 17]          82,944\n",
            "      BatchNorm2d-94           [-1, 96, 17, 17]             192\n",
            "      BasicConv2d-95           [-1, 96, 17, 17]               0\n",
            "       InceptionB-96          [-1, 768, 17, 17]               0\n",
            "           Conv2d-97          [-1, 192, 17, 17]         147,456\n",
            "      BatchNorm2d-98          [-1, 192, 17, 17]             384\n",
            "      BasicConv2d-99          [-1, 192, 17, 17]               0\n",
            "          Conv2d-100          [-1, 128, 17, 17]          98,304\n",
            "     BatchNorm2d-101          [-1, 128, 17, 17]             256\n",
            "     BasicConv2d-102          [-1, 128, 17, 17]               0\n",
            "          Conv2d-103          [-1, 128, 17, 17]         114,688\n",
            "     BatchNorm2d-104          [-1, 128, 17, 17]             256\n",
            "     BasicConv2d-105          [-1, 128, 17, 17]               0\n",
            "          Conv2d-106          [-1, 192, 17, 17]         172,032\n",
            "     BatchNorm2d-107          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-108          [-1, 192, 17, 17]               0\n",
            "          Conv2d-109          [-1, 128, 17, 17]          98,304\n",
            "     BatchNorm2d-110          [-1, 128, 17, 17]             256\n",
            "     BasicConv2d-111          [-1, 128, 17, 17]               0\n",
            "          Conv2d-112          [-1, 128, 17, 17]         114,688\n",
            "     BatchNorm2d-113          [-1, 128, 17, 17]             256\n",
            "     BasicConv2d-114          [-1, 128, 17, 17]               0\n",
            "          Conv2d-115          [-1, 128, 17, 17]         114,688\n",
            "     BatchNorm2d-116          [-1, 128, 17, 17]             256\n",
            "     BasicConv2d-117          [-1, 128, 17, 17]               0\n",
            "          Conv2d-118          [-1, 128, 17, 17]         114,688\n",
            "     BatchNorm2d-119          [-1, 128, 17, 17]             256\n",
            "     BasicConv2d-120          [-1, 128, 17, 17]               0\n",
            "          Conv2d-121          [-1, 192, 17, 17]         172,032\n",
            "     BatchNorm2d-122          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-123          [-1, 192, 17, 17]               0\n",
            "          Conv2d-124          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-125          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-126          [-1, 192, 17, 17]               0\n",
            "      InceptionC-127          [-1, 768, 17, 17]               0\n",
            "          Conv2d-128          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-129          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-130          [-1, 192, 17, 17]               0\n",
            "          Conv2d-131          [-1, 160, 17, 17]         122,880\n",
            "     BatchNorm2d-132          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-133          [-1, 160, 17, 17]               0\n",
            "          Conv2d-134          [-1, 160, 17, 17]         179,200\n",
            "     BatchNorm2d-135          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-136          [-1, 160, 17, 17]               0\n",
            "          Conv2d-137          [-1, 192, 17, 17]         215,040\n",
            "     BatchNorm2d-138          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-139          [-1, 192, 17, 17]               0\n",
            "          Conv2d-140          [-1, 160, 17, 17]         122,880\n",
            "     BatchNorm2d-141          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-142          [-1, 160, 17, 17]               0\n",
            "          Conv2d-143          [-1, 160, 17, 17]         179,200\n",
            "     BatchNorm2d-144          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-145          [-1, 160, 17, 17]               0\n",
            "          Conv2d-146          [-1, 160, 17, 17]         179,200\n",
            "     BatchNorm2d-147          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-148          [-1, 160, 17, 17]               0\n",
            "          Conv2d-149          [-1, 160, 17, 17]         179,200\n",
            "     BatchNorm2d-150          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-151          [-1, 160, 17, 17]               0\n",
            "          Conv2d-152          [-1, 192, 17, 17]         215,040\n",
            "     BatchNorm2d-153          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-154          [-1, 192, 17, 17]               0\n",
            "          Conv2d-155          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-156          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-157          [-1, 192, 17, 17]               0\n",
            "      InceptionC-158          [-1, 768, 17, 17]               0\n",
            "          Conv2d-159          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-160          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-161          [-1, 192, 17, 17]               0\n",
            "          Conv2d-162          [-1, 160, 17, 17]         122,880\n",
            "     BatchNorm2d-163          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-164          [-1, 160, 17, 17]               0\n",
            "          Conv2d-165          [-1, 160, 17, 17]         179,200\n",
            "     BatchNorm2d-166          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-167          [-1, 160, 17, 17]               0\n",
            "          Conv2d-168          [-1, 192, 17, 17]         215,040\n",
            "     BatchNorm2d-169          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-170          [-1, 192, 17, 17]               0\n",
            "          Conv2d-171          [-1, 160, 17, 17]         122,880\n",
            "     BatchNorm2d-172          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-173          [-1, 160, 17, 17]               0\n",
            "          Conv2d-174          [-1, 160, 17, 17]         179,200\n",
            "     BatchNorm2d-175          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-176          [-1, 160, 17, 17]               0\n",
            "          Conv2d-177          [-1, 160, 17, 17]         179,200\n",
            "     BatchNorm2d-178          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-179          [-1, 160, 17, 17]               0\n",
            "          Conv2d-180          [-1, 160, 17, 17]         179,200\n",
            "     BatchNorm2d-181          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-182          [-1, 160, 17, 17]               0\n",
            "          Conv2d-183          [-1, 192, 17, 17]         215,040\n",
            "     BatchNorm2d-184          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-185          [-1, 192, 17, 17]               0\n",
            "          Conv2d-186          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-187          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-188          [-1, 192, 17, 17]               0\n",
            "      InceptionC-189          [-1, 768, 17, 17]               0\n",
            "          Conv2d-190          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-191          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-192          [-1, 192, 17, 17]               0\n",
            "          Conv2d-193          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-194          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-195          [-1, 192, 17, 17]               0\n",
            "          Conv2d-196          [-1, 192, 17, 17]         258,048\n",
            "     BatchNorm2d-197          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-198          [-1, 192, 17, 17]               0\n",
            "          Conv2d-199          [-1, 192, 17, 17]         258,048\n",
            "     BatchNorm2d-200          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-201          [-1, 192, 17, 17]               0\n",
            "          Conv2d-202          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-203          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-204          [-1, 192, 17, 17]               0\n",
            "          Conv2d-205          [-1, 192, 17, 17]         258,048\n",
            "     BatchNorm2d-206          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-207          [-1, 192, 17, 17]               0\n",
            "          Conv2d-208          [-1, 192, 17, 17]         258,048\n",
            "     BatchNorm2d-209          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-210          [-1, 192, 17, 17]               0\n",
            "          Conv2d-211          [-1, 192, 17, 17]         258,048\n",
            "     BatchNorm2d-212          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-213          [-1, 192, 17, 17]               0\n",
            "          Conv2d-214          [-1, 192, 17, 17]         258,048\n",
            "     BatchNorm2d-215          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-216          [-1, 192, 17, 17]               0\n",
            "          Conv2d-217          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-218          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-219          [-1, 192, 17, 17]               0\n",
            "      InceptionC-220          [-1, 768, 17, 17]               0\n",
            "          Conv2d-221            [-1, 128, 5, 5]          98,304\n",
            "     BatchNorm2d-222            [-1, 128, 5, 5]             256\n",
            "     BasicConv2d-223            [-1, 128, 5, 5]               0\n",
            "          Conv2d-224            [-1, 768, 1, 1]       2,457,600\n",
            "     BatchNorm2d-225            [-1, 768, 1, 1]           1,536\n",
            "     BasicConv2d-226            [-1, 768, 1, 1]               0\n",
            "          Linear-227                 [-1, 1000]         769,000\n",
            "    InceptionAux-228                 [-1, 1000]               0\n",
            "          Conv2d-229          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-230          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-231          [-1, 192, 17, 17]               0\n",
            "          Conv2d-232            [-1, 320, 8, 8]         552,960\n",
            "     BatchNorm2d-233            [-1, 320, 8, 8]             640\n",
            "     BasicConv2d-234            [-1, 320, 8, 8]               0\n",
            "          Conv2d-235          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-236          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-237          [-1, 192, 17, 17]               0\n",
            "          Conv2d-238          [-1, 192, 17, 17]         258,048\n",
            "     BatchNorm2d-239          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-240          [-1, 192, 17, 17]               0\n",
            "          Conv2d-241          [-1, 192, 17, 17]         258,048\n",
            "     BatchNorm2d-242          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-243          [-1, 192, 17, 17]               0\n",
            "          Conv2d-244            [-1, 192, 8, 8]         331,776\n",
            "     BatchNorm2d-245            [-1, 192, 8, 8]             384\n",
            "     BasicConv2d-246            [-1, 192, 8, 8]               0\n",
            "      InceptionD-247           [-1, 1280, 8, 8]               0\n",
            "          Conv2d-248            [-1, 320, 8, 8]         409,600\n",
            "     BatchNorm2d-249            [-1, 320, 8, 8]             640\n",
            "     BasicConv2d-250            [-1, 320, 8, 8]               0\n",
            "          Conv2d-251            [-1, 384, 8, 8]         491,520\n",
            "     BatchNorm2d-252            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-253            [-1, 384, 8, 8]               0\n",
            "          Conv2d-254            [-1, 384, 8, 8]         442,368\n",
            "     BatchNorm2d-255            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-256            [-1, 384, 8, 8]               0\n",
            "          Conv2d-257            [-1, 384, 8, 8]         442,368\n",
            "     BatchNorm2d-258            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-259            [-1, 384, 8, 8]               0\n",
            "          Conv2d-260            [-1, 448, 8, 8]         573,440\n",
            "     BatchNorm2d-261            [-1, 448, 8, 8]             896\n",
            "     BasicConv2d-262            [-1, 448, 8, 8]               0\n",
            "          Conv2d-263            [-1, 384, 8, 8]       1,548,288\n",
            "     BatchNorm2d-264            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-265            [-1, 384, 8, 8]               0\n",
            "          Conv2d-266            [-1, 384, 8, 8]         442,368\n",
            "     BatchNorm2d-267            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-268            [-1, 384, 8, 8]               0\n",
            "          Conv2d-269            [-1, 384, 8, 8]         442,368\n",
            "     BatchNorm2d-270            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-271            [-1, 384, 8, 8]               0\n",
            "          Conv2d-272            [-1, 192, 8, 8]         245,760\n",
            "     BatchNorm2d-273            [-1, 192, 8, 8]             384\n",
            "     BasicConv2d-274            [-1, 192, 8, 8]               0\n",
            "      InceptionE-275           [-1, 2048, 8, 8]               0\n",
            "          Conv2d-276            [-1, 320, 8, 8]         655,360\n",
            "     BatchNorm2d-277            [-1, 320, 8, 8]             640\n",
            "     BasicConv2d-278            [-1, 320, 8, 8]               0\n",
            "          Conv2d-279            [-1, 384, 8, 8]         786,432\n",
            "     BatchNorm2d-280            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-281            [-1, 384, 8, 8]               0\n",
            "          Conv2d-282            [-1, 384, 8, 8]         442,368\n",
            "     BatchNorm2d-283            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-284            [-1, 384, 8, 8]               0\n",
            "          Conv2d-285            [-1, 384, 8, 8]         442,368\n",
            "     BatchNorm2d-286            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-287            [-1, 384, 8, 8]               0\n",
            "          Conv2d-288            [-1, 448, 8, 8]         917,504\n",
            "     BatchNorm2d-289            [-1, 448, 8, 8]             896\n",
            "     BasicConv2d-290            [-1, 448, 8, 8]               0\n",
            "          Conv2d-291            [-1, 384, 8, 8]       1,548,288\n",
            "     BatchNorm2d-292            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-293            [-1, 384, 8, 8]               0\n",
            "          Conv2d-294            [-1, 384, 8, 8]         442,368\n",
            "     BatchNorm2d-295            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-296            [-1, 384, 8, 8]               0\n",
            "          Conv2d-297            [-1, 384, 8, 8]         442,368\n",
            "     BatchNorm2d-298            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-299            [-1, 384, 8, 8]               0\n",
            "          Conv2d-300            [-1, 192, 8, 8]         393,216\n",
            "     BatchNorm2d-301            [-1, 192, 8, 8]             384\n",
            "     BasicConv2d-302            [-1, 192, 8, 8]               0\n",
            "      InceptionE-303           [-1, 2048, 8, 8]               0\n",
            "AdaptiveAvgPool2d-304           [-1, 2048, 1, 1]               0\n",
            "         Dropout-305           [-1, 2048, 1, 1]               0\n",
            "          Linear-306                 [-1, 1000]       2,049,000\n",
            "================================================================\n",
            "Total params: 27,161,264\n",
            "Trainable params: 27,161,264\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.02\n",
            "Forward/backward pass size (MB): 228.66\n",
            "Params size (MB): 103.61\n",
            "Estimated Total Size (MB): 333.29\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.optim import RMSprop\n",
        "\n",
        "# Load the pre-trained Inception V3 model\n",
        "pre_trained_model = models.inception_v3(pretrained=True, aux_logits=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "pre_trained_model.to(device)\n",
        "\n",
        "def print_model_summary(model):\n",
        "    for name, module in model.named_modules():\n",
        "        print(f\"{name} : {module.__class__.__name__}\")\n",
        "\n",
        "# Example of how to use the function with your pre-trained model\n",
        "print_model_summary(pre_trained_model)\n",
        "\n",
        "from torchsummary import summary\n",
        "summary(pre_trained_model, input_size=(3, 299, 299))  # (Channels, Height, Width)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "qGM9T6yI1QjJ"
      },
      "outputs": [],
      "source": [
        "# Freeze all layers up to and including the 'Mixed_7c'\n",
        "for name, parameter in pre_trained_model.named_parameters():\n",
        "    parameter.requires_grad = False\n",
        "    if 'Mixed_7c' in name:\n",
        "        break\n",
        "\n",
        "# Modify the existing fully connected layer\n",
        "num_ftrs = pre_trained_model.fc.in_features\n",
        "pre_trained_model.fc = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 1024),  # New fully connected layer with 1024 outputs\n",
        "    nn.ReLU(),                # Activation layer\n",
        "    nn.Linear(1024, 2)         # Final layer for binary classification\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((299, 299)),  # Resize to match Inception V3 input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load datasets using ImageFolder\n",
        "train_dataset = ImageFolder(root=training_dir, transform=transform)\n",
        "val_dataset = ImageFolder(root=validation_dir, transform=transform)\n",
        "\n",
        "# Data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, train_loader, num_epochs=10):\n",
        "    model.train()  # Set the model to training mode\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            # Handle multiple outputs for training with auxiliary logits\n",
        "            if isinstance(outputs, tuple):\n",
        "                output, aux_output = outputs\n",
        "                loss1 = criterion(output, labels)\n",
        "                loss2 = criterion(aux_output, labels)\n",
        "                loss = loss1 + 0.4 * loss2  # Scale the auxiliary loss as is standard for Inception\n",
        "            else:\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            _, preds = torch.max(output, 1)  # Ensure you use the main output for accuracy calculation\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels).item()\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_acc = running_corrects / len(train_loader.dataset)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "w7ylKrDXGWTZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3 - Loss: 4.2077, Acc: 0.9513\n",
            "Epoch 2/3 - Loss: 3.4964, Acc: 0.9942\n",
            "Epoch 3/3 - Loss: 3.4556, Acc: 0.9981\n"
          ]
        }
      ],
      "source": [
        "# Only optimize parameters that are set to be trainable\n",
        "optimizer = RMSprop(filter(lambda p: p.requires_grad, pre_trained_model.parameters()), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model\n",
        "train_model(pre_trained_model, criterion, optimizer, train_loader, num_epochs=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "wtzZYi2p4BfX"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, data_loader, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total = 0\n",
        "    corrects = 0\n",
        "\n",
        "    with torch.no_grad():  # No need to track gradients for evaluation\n",
        "        for inputs, labels in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            # Handle multiple outputs during evaluation\n",
        "            if isinstance(outputs, tuple):\n",
        "                outputs = outputs[0]  # Use only the main output for evaluation\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            corrects += torch.sum(preds == labels).item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    accuracy = corrects / total\n",
        "    print(f'Accuracy on the validation set: {accuracy:.4f} ({corrects}/{total})')\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Assuming the necessary imports and pre_trained_model are defined and set up\n",
        "# # Ensure the model and data loaders are on the appropriate device\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# pre_trained_model = pre_trained_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on the validation set: 0.9414 (241/256)\n"
          ]
        }
      ],
      "source": [
        "# Assuming val_loader is defined and set up as previously shown\n",
        "accuracy = evaluate_model(pre_trained_model, val_loader, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHnqIjfNEGEC"
      },
      "source": [
        "# Cats versus Dogs\n",
        "(Note the following cells will only work if you have already run the above cells for training Horses v Humans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKUqD0cUEHxY"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O \"cats_and_dogs_filtered.zip\"\n",
        "\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"cats_and_dogs_filtered.zip\", 'r')\n",
        "zip_ref.extractall(\"/tmp\")\n",
        "zip_ref.close()\n",
        "\n",
        "training_dir = \"/tmp/cats_and_dogs_filtered/train/\"\n",
        "validation_dir = \"/tmp/cats_and_dogs_filtered/validation/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96xx7VsnGjCq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.optim import RMSprop\n",
        "\n",
        "# Load the pre-trained Inception V3 model\n",
        "pre_trained_model = models.inception_v3(pretrained=True, aux_logits=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "pre_trained_model.to(device)\n",
        "\n",
        "def print_model_summary(model):\n",
        "    for name, module in model.named_modules():\n",
        "        print(f\"{name} : {module.__class__.__name__}\")\n",
        "\n",
        "\n",
        "# Example of how to use the function with your pre-trained model\n",
        "print_model_summary(pre_trained_model)\n",
        "\n",
        "from torchsummary import summary\n",
        "summary(pre_trained_model, input_size=(3, 299, 299))  # (Channels, Height, Width)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1ED78kfFnFn"
      },
      "outputs": [],
      "source": [
        "# Freeze all layers up to and including the 'Mixed_7c'\n",
        "for name, parameter in pre_trained_model.named_parameters():\n",
        "    parameter.requires_grad = False\n",
        "    if 'Mixed_7c' in name:\n",
        "        break\n",
        "\n",
        "# Modify the existing fully connected layer\n",
        "num_ftrs = pre_trained_model.fc.in_features\n",
        "pre_trained_model.fc = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 1024),  # New fully connected layer with 1024 outputs\n",
        "    nn.ReLU(),                # Activation layer\n",
        "    nn.Linear(1024, 2)         # Final layer for binary classification\n",
        ")\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((299, 299)),  # Resize to match Inception V3 input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "# Load datasets using ImageFolder\n",
        "train_dataset = ImageFolder(root=training_dir, transform=transform)\n",
        "val_dataset = ImageFolder(root=validation_dir, transform=transform)\n",
        "\n",
        "# Data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "def train_model(model, criterion, optimizer, train_loader, num_epochs=10):\n",
        "    model.train()  # Set the model to training mode\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            # Handle multiple outputs for training with auxiliary logits\n",
        "            if isinstance(outputs, tuple):\n",
        "                output, aux_output = outputs\n",
        "                loss1 = criterion(output, labels)\n",
        "                loss2 = criterion(aux_output, labels)\n",
        "                loss = loss1 + 0.4 * loss2  # Scale the auxiliary loss as is standard for Inception\n",
        "            else:\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            _, preds = torch.max(output, 1)  # Ensure you use the main output for accuracy calculation\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels).item()\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_acc = running_corrects / len(train_loader.dataset)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGUwiuwzHgom"
      },
      "outputs": [],
      "source": [
        "# Only optimize parameters that are set to be trainable\n",
        "optimizer = RMSprop(filter(lambda p: p.requires_grad, pre_trained_model.parameters()), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model\n",
        "train_model(pre_trained_model, criterion, optimizer, train_loader, num_epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeH1rViALqPp"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, data_loader, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total = 0\n",
        "    corrects = 0\n",
        "\n",
        "    with torch.no_grad():  # No need to track gradients for evaluation\n",
        "        for inputs, labels in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            # Handle multiple outputs during evaluation\n",
        "            if isinstance(outputs, tuple):\n",
        "                outputs = outputs[0]  # Use only the main output for evaluation\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            corrects += torch.sum(preds == labels).item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    accuracy = corrects / total\n",
        "    print(f'Accuracy on the validation set: {accuracy:.4f} ({corrects}/{total})')\n",
        "    return accuracy\n",
        "\n",
        "# Assuming the necessary imports and pre_trained_model are defined and set up\n",
        "# Ensure the model and data loaders are on the appropriate device\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "pre_trained_model = pre_trained_model.to(device)\n",
        "\n",
        "# Assuming val_loader is defined and set up as previously shown\n",
        "\n",
        "accuracy = evaluate_model(pre_trained_model, val_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zv4qoQBqL9Xp"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "def load_image(image_path, transform):\n",
        "    # Load image\n",
        "    image = Image.open(image_path).convert('RGB')  # Convert to RGB just in case it's not\n",
        "    # Apply transformations\n",
        "    image = transform(image)\n",
        "    # Add batch dimension, as the model expects batches\n",
        "    image = image.unsqueeze(0)\n",
        "    return image\n",
        "\n",
        "    # Prediction function\n",
        "def predict(image_path, model, device, transform):\n",
        "    model.eval()\n",
        "    image = load_image(image_path, transform)\n",
        "    image = image.to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "        print(output)\n",
        "        prediction = torch.max(output, 1)\n",
        "        print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEPsQDrUMNXh"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "for img in uploaded.keys():\n",
        "  predict(img, pre_trained_model, device, transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rZh6cCkPOWg"
      },
      "source": [
        "# Rock Paper Scissors\n",
        "\n",
        "## Data\n",
        "### Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "7iRGV8k1PNks"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-12-04 10:57:13--  https://storage.googleapis.com/learning-datasets/rps.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.200.91, 216.58.215.187, 142.250.178.187, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.200.91|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 200682221 (191M) [application/zip]\n",
            "Saving to: rps.zip\n",
            "\n",
            "rps.zip              24%[===>                ]  46.11M  3.54MB/s    eta 47s    ^C\n"
          ]
        },
        {
          "ename": "BadZipFile",
          "evalue": "File is not a zip file",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mBadZipFile\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mzipfile\u001b[39;00m\n\u001b[32m      4\u001b[39m get_ipython().system(\u001b[33m'\u001b[39m\u001b[33mwget --no-check-certificate      https://storage.googleapis.com/learning-datasets/rps.zip -O \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mrps.zip\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m zip_ref = \u001b[43mzipfile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrps.zip\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m zip_ref.extractall(\u001b[33m\"\u001b[39m\u001b[33m/tmp\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m zip_ref.close()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch/lib/python3.12/zipfile/__init__.py:1370\u001b[39m, in \u001b[36mZipFile.__init__\u001b[39m\u001b[34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[39m\n\u001b[32m   1368\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1369\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1370\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_RealGetContents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1371\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mx\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m   1372\u001b[39m         \u001b[38;5;66;03m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[32m   1373\u001b[39m         \u001b[38;5;66;03m# even if no files are added to the archive\u001b[39;00m\n\u001b[32m   1374\u001b[39m         \u001b[38;5;28mself\u001b[39m._didModify = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch/lib/python3.12/zipfile/__init__.py:1437\u001b[39m, in \u001b[36mZipFile._RealGetContents\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1435\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[33m\"\u001b[39m\u001b[33mFile is not a zip file\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1436\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m endrec:\n\u001b[32m-> \u001b[39m\u001b[32m1437\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[33m\"\u001b[39m\u001b[33mFile is not a zip file\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1438\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.debug > \u001b[32m1\u001b[39m:\n\u001b[32m   1439\u001b[39m     \u001b[38;5;28mprint\u001b[39m(endrec)\n",
            "\u001b[31mBadZipFile\u001b[39m: File is not a zip file"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/learning-datasets/rps.zip -O \"rps.zip\"\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"rps.zip\", 'r')\n",
        "zip_ref.extractall(\"/tmp\")\n",
        "zip_ref.close()\n",
        "\n",
        "training_dir = \"/tmp/rps/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((299, 299)),  # Resize to match Inception V3 input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load datasets using ImageFolder\n",
        "train_dataset = ImageFolder(root=training_dir, transform=transform)\n",
        "val_dataset = ImageFolder(root=validation_dir, transform=transform)\n",
        "\n",
        "# Data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model\n",
        "\n",
        "### Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "AZzlhyIoPuJR"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/casadoj/miniconda3/envs/torch/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/home/casadoj/miniconda3/envs/torch/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " : Inception3\n",
            "Conv2d_1a_3x3 : BasicConv2d\n",
            "Conv2d_1a_3x3.conv : Conv2d\n",
            "Conv2d_1a_3x3.bn : BatchNorm2d\n",
            "Conv2d_2a_3x3 : BasicConv2d\n",
            "Conv2d_2a_3x3.conv : Conv2d\n",
            "Conv2d_2a_3x3.bn : BatchNorm2d\n",
            "Conv2d_2b_3x3 : BasicConv2d\n",
            "Conv2d_2b_3x3.conv : Conv2d\n",
            "Conv2d_2b_3x3.bn : BatchNorm2d\n",
            "maxpool1 : MaxPool2d\n",
            "Conv2d_3b_1x1 : BasicConv2d\n",
            "Conv2d_3b_1x1.conv : Conv2d\n",
            "Conv2d_3b_1x1.bn : BatchNorm2d\n",
            "Conv2d_4a_3x3 : BasicConv2d\n",
            "Conv2d_4a_3x3.conv : Conv2d\n",
            "Conv2d_4a_3x3.bn : BatchNorm2d\n",
            "maxpool2 : MaxPool2d\n",
            "Mixed_5b : InceptionA\n",
            "Mixed_5b.branch1x1 : BasicConv2d\n",
            "Mixed_5b.branch1x1.conv : Conv2d\n",
            "Mixed_5b.branch1x1.bn : BatchNorm2d\n",
            "Mixed_5b.branch5x5_1 : BasicConv2d\n",
            "Mixed_5b.branch5x5_1.conv : Conv2d\n",
            "Mixed_5b.branch5x5_1.bn : BatchNorm2d\n",
            "Mixed_5b.branch5x5_2 : BasicConv2d\n",
            "Mixed_5b.branch5x5_2.conv : Conv2d\n",
            "Mixed_5b.branch5x5_2.bn : BatchNorm2d\n",
            "Mixed_5b.branch3x3dbl_1 : BasicConv2d\n",
            "Mixed_5b.branch3x3dbl_1.conv : Conv2d\n",
            "Mixed_5b.branch3x3dbl_1.bn : BatchNorm2d\n",
            "Mixed_5b.branch3x3dbl_2 : BasicConv2d\n",
            "Mixed_5b.branch3x3dbl_2.conv : Conv2d\n",
            "Mixed_5b.branch3x3dbl_2.bn : BatchNorm2d\n",
            "Mixed_5b.branch3x3dbl_3 : BasicConv2d\n",
            "Mixed_5b.branch3x3dbl_3.conv : Conv2d\n",
            "Mixed_5b.branch3x3dbl_3.bn : BatchNorm2d\n",
            "Mixed_5b.branch_pool : BasicConv2d\n",
            "Mixed_5b.branch_pool.conv : Conv2d\n",
            "Mixed_5b.branch_pool.bn : BatchNorm2d\n",
            "Mixed_5c : InceptionA\n",
            "Mixed_5c.branch1x1 : BasicConv2d\n",
            "Mixed_5c.branch1x1.conv : Conv2d\n",
            "Mixed_5c.branch1x1.bn : BatchNorm2d\n",
            "Mixed_5c.branch5x5_1 : BasicConv2d\n",
            "Mixed_5c.branch5x5_1.conv : Conv2d\n",
            "Mixed_5c.branch5x5_1.bn : BatchNorm2d\n",
            "Mixed_5c.branch5x5_2 : BasicConv2d\n",
            "Mixed_5c.branch5x5_2.conv : Conv2d\n",
            "Mixed_5c.branch5x5_2.bn : BatchNorm2d\n",
            "Mixed_5c.branch3x3dbl_1 : BasicConv2d\n",
            "Mixed_5c.branch3x3dbl_1.conv : Conv2d\n",
            "Mixed_5c.branch3x3dbl_1.bn : BatchNorm2d\n",
            "Mixed_5c.branch3x3dbl_2 : BasicConv2d\n",
            "Mixed_5c.branch3x3dbl_2.conv : Conv2d\n",
            "Mixed_5c.branch3x3dbl_2.bn : BatchNorm2d\n",
            "Mixed_5c.branch3x3dbl_3 : BasicConv2d\n",
            "Mixed_5c.branch3x3dbl_3.conv : Conv2d\n",
            "Mixed_5c.branch3x3dbl_3.bn : BatchNorm2d\n",
            "Mixed_5c.branch_pool : BasicConv2d\n",
            "Mixed_5c.branch_pool.conv : Conv2d\n",
            "Mixed_5c.branch_pool.bn : BatchNorm2d\n",
            "Mixed_5d : InceptionA\n",
            "Mixed_5d.branch1x1 : BasicConv2d\n",
            "Mixed_5d.branch1x1.conv : Conv2d\n",
            "Mixed_5d.branch1x1.bn : BatchNorm2d\n",
            "Mixed_5d.branch5x5_1 : BasicConv2d\n",
            "Mixed_5d.branch5x5_1.conv : Conv2d\n",
            "Mixed_5d.branch5x5_1.bn : BatchNorm2d\n",
            "Mixed_5d.branch5x5_2 : BasicConv2d\n",
            "Mixed_5d.branch5x5_2.conv : Conv2d\n",
            "Mixed_5d.branch5x5_2.bn : BatchNorm2d\n",
            "Mixed_5d.branch3x3dbl_1 : BasicConv2d\n",
            "Mixed_5d.branch3x3dbl_1.conv : Conv2d\n",
            "Mixed_5d.branch3x3dbl_1.bn : BatchNorm2d\n",
            "Mixed_5d.branch3x3dbl_2 : BasicConv2d\n",
            "Mixed_5d.branch3x3dbl_2.conv : Conv2d\n",
            "Mixed_5d.branch3x3dbl_2.bn : BatchNorm2d\n",
            "Mixed_5d.branch3x3dbl_3 : BasicConv2d\n",
            "Mixed_5d.branch3x3dbl_3.conv : Conv2d\n",
            "Mixed_5d.branch3x3dbl_3.bn : BatchNorm2d\n",
            "Mixed_5d.branch_pool : BasicConv2d\n",
            "Mixed_5d.branch_pool.conv : Conv2d\n",
            "Mixed_5d.branch_pool.bn : BatchNorm2d\n",
            "Mixed_6a : InceptionB\n",
            "Mixed_6a.branch3x3 : BasicConv2d\n",
            "Mixed_6a.branch3x3.conv : Conv2d\n",
            "Mixed_6a.branch3x3.bn : BatchNorm2d\n",
            "Mixed_6a.branch3x3dbl_1 : BasicConv2d\n",
            "Mixed_6a.branch3x3dbl_1.conv : Conv2d\n",
            "Mixed_6a.branch3x3dbl_1.bn : BatchNorm2d\n",
            "Mixed_6a.branch3x3dbl_2 : BasicConv2d\n",
            "Mixed_6a.branch3x3dbl_2.conv : Conv2d\n",
            "Mixed_6a.branch3x3dbl_2.bn : BatchNorm2d\n",
            "Mixed_6a.branch3x3dbl_3 : BasicConv2d\n",
            "Mixed_6a.branch3x3dbl_3.conv : Conv2d\n",
            "Mixed_6a.branch3x3dbl_3.bn : BatchNorm2d\n",
            "Mixed_6b : InceptionC\n",
            "Mixed_6b.branch1x1 : BasicConv2d\n",
            "Mixed_6b.branch1x1.conv : Conv2d\n",
            "Mixed_6b.branch1x1.bn : BatchNorm2d\n",
            "Mixed_6b.branch7x7_1 : BasicConv2d\n",
            "Mixed_6b.branch7x7_1.conv : Conv2d\n",
            "Mixed_6b.branch7x7_1.bn : BatchNorm2d\n",
            "Mixed_6b.branch7x7_2 : BasicConv2d\n",
            "Mixed_6b.branch7x7_2.conv : Conv2d\n",
            "Mixed_6b.branch7x7_2.bn : BatchNorm2d\n",
            "Mixed_6b.branch7x7_3 : BasicConv2d\n",
            "Mixed_6b.branch7x7_3.conv : Conv2d\n",
            "Mixed_6b.branch7x7_3.bn : BatchNorm2d\n",
            "Mixed_6b.branch7x7dbl_1 : BasicConv2d\n",
            "Mixed_6b.branch7x7dbl_1.conv : Conv2d\n",
            "Mixed_6b.branch7x7dbl_1.bn : BatchNorm2d\n",
            "Mixed_6b.branch7x7dbl_2 : BasicConv2d\n",
            "Mixed_6b.branch7x7dbl_2.conv : Conv2d\n",
            "Mixed_6b.branch7x7dbl_2.bn : BatchNorm2d\n",
            "Mixed_6b.branch7x7dbl_3 : BasicConv2d\n",
            "Mixed_6b.branch7x7dbl_3.conv : Conv2d\n",
            "Mixed_6b.branch7x7dbl_3.bn : BatchNorm2d\n",
            "Mixed_6b.branch7x7dbl_4 : BasicConv2d\n",
            "Mixed_6b.branch7x7dbl_4.conv : Conv2d\n",
            "Mixed_6b.branch7x7dbl_4.bn : BatchNorm2d\n",
            "Mixed_6b.branch7x7dbl_5 : BasicConv2d\n",
            "Mixed_6b.branch7x7dbl_5.conv : Conv2d\n",
            "Mixed_6b.branch7x7dbl_5.bn : BatchNorm2d\n",
            "Mixed_6b.branch_pool : BasicConv2d\n",
            "Mixed_6b.branch_pool.conv : Conv2d\n",
            "Mixed_6b.branch_pool.bn : BatchNorm2d\n",
            "Mixed_6c : InceptionC\n",
            "Mixed_6c.branch1x1 : BasicConv2d\n",
            "Mixed_6c.branch1x1.conv : Conv2d\n",
            "Mixed_6c.branch1x1.bn : BatchNorm2d\n",
            "Mixed_6c.branch7x7_1 : BasicConv2d\n",
            "Mixed_6c.branch7x7_1.conv : Conv2d\n",
            "Mixed_6c.branch7x7_1.bn : BatchNorm2d\n",
            "Mixed_6c.branch7x7_2 : BasicConv2d\n",
            "Mixed_6c.branch7x7_2.conv : Conv2d\n",
            "Mixed_6c.branch7x7_2.bn : BatchNorm2d\n",
            "Mixed_6c.branch7x7_3 : BasicConv2d\n",
            "Mixed_6c.branch7x7_3.conv : Conv2d\n",
            "Mixed_6c.branch7x7_3.bn : BatchNorm2d\n",
            "Mixed_6c.branch7x7dbl_1 : BasicConv2d\n",
            "Mixed_6c.branch7x7dbl_1.conv : Conv2d\n",
            "Mixed_6c.branch7x7dbl_1.bn : BatchNorm2d\n",
            "Mixed_6c.branch7x7dbl_2 : BasicConv2d\n",
            "Mixed_6c.branch7x7dbl_2.conv : Conv2d\n",
            "Mixed_6c.branch7x7dbl_2.bn : BatchNorm2d\n",
            "Mixed_6c.branch7x7dbl_3 : BasicConv2d\n",
            "Mixed_6c.branch7x7dbl_3.conv : Conv2d\n",
            "Mixed_6c.branch7x7dbl_3.bn : BatchNorm2d\n",
            "Mixed_6c.branch7x7dbl_4 : BasicConv2d\n",
            "Mixed_6c.branch7x7dbl_4.conv : Conv2d\n",
            "Mixed_6c.branch7x7dbl_4.bn : BatchNorm2d\n",
            "Mixed_6c.branch7x7dbl_5 : BasicConv2d\n",
            "Mixed_6c.branch7x7dbl_5.conv : Conv2d\n",
            "Mixed_6c.branch7x7dbl_5.bn : BatchNorm2d\n",
            "Mixed_6c.branch_pool : BasicConv2d\n",
            "Mixed_6c.branch_pool.conv : Conv2d\n",
            "Mixed_6c.branch_pool.bn : BatchNorm2d\n",
            "Mixed_6d : InceptionC\n",
            "Mixed_6d.branch1x1 : BasicConv2d\n",
            "Mixed_6d.branch1x1.conv : Conv2d\n",
            "Mixed_6d.branch1x1.bn : BatchNorm2d\n",
            "Mixed_6d.branch7x7_1 : BasicConv2d\n",
            "Mixed_6d.branch7x7_1.conv : Conv2d\n",
            "Mixed_6d.branch7x7_1.bn : BatchNorm2d\n",
            "Mixed_6d.branch7x7_2 : BasicConv2d\n",
            "Mixed_6d.branch7x7_2.conv : Conv2d\n",
            "Mixed_6d.branch7x7_2.bn : BatchNorm2d\n",
            "Mixed_6d.branch7x7_3 : BasicConv2d\n",
            "Mixed_6d.branch7x7_3.conv : Conv2d\n",
            "Mixed_6d.branch7x7_3.bn : BatchNorm2d\n",
            "Mixed_6d.branch7x7dbl_1 : BasicConv2d\n",
            "Mixed_6d.branch7x7dbl_1.conv : Conv2d\n",
            "Mixed_6d.branch7x7dbl_1.bn : BatchNorm2d\n",
            "Mixed_6d.branch7x7dbl_2 : BasicConv2d\n",
            "Mixed_6d.branch7x7dbl_2.conv : Conv2d\n",
            "Mixed_6d.branch7x7dbl_2.bn : BatchNorm2d\n",
            "Mixed_6d.branch7x7dbl_3 : BasicConv2d\n",
            "Mixed_6d.branch7x7dbl_3.conv : Conv2d\n",
            "Mixed_6d.branch7x7dbl_3.bn : BatchNorm2d\n",
            "Mixed_6d.branch7x7dbl_4 : BasicConv2d\n",
            "Mixed_6d.branch7x7dbl_4.conv : Conv2d\n",
            "Mixed_6d.branch7x7dbl_4.bn : BatchNorm2d\n",
            "Mixed_6d.branch7x7dbl_5 : BasicConv2d\n",
            "Mixed_6d.branch7x7dbl_5.conv : Conv2d\n",
            "Mixed_6d.branch7x7dbl_5.bn : BatchNorm2d\n",
            "Mixed_6d.branch_pool : BasicConv2d\n",
            "Mixed_6d.branch_pool.conv : Conv2d\n",
            "Mixed_6d.branch_pool.bn : BatchNorm2d\n",
            "Mixed_6e : InceptionC\n",
            "Mixed_6e.branch1x1 : BasicConv2d\n",
            "Mixed_6e.branch1x1.conv : Conv2d\n",
            "Mixed_6e.branch1x1.bn : BatchNorm2d\n",
            "Mixed_6e.branch7x7_1 : BasicConv2d\n",
            "Mixed_6e.branch7x7_1.conv : Conv2d\n",
            "Mixed_6e.branch7x7_1.bn : BatchNorm2d\n",
            "Mixed_6e.branch7x7_2 : BasicConv2d\n",
            "Mixed_6e.branch7x7_2.conv : Conv2d\n",
            "Mixed_6e.branch7x7_2.bn : BatchNorm2d\n",
            "Mixed_6e.branch7x7_3 : BasicConv2d\n",
            "Mixed_6e.branch7x7_3.conv : Conv2d\n",
            "Mixed_6e.branch7x7_3.bn : BatchNorm2d\n",
            "Mixed_6e.branch7x7dbl_1 : BasicConv2d\n",
            "Mixed_6e.branch7x7dbl_1.conv : Conv2d\n",
            "Mixed_6e.branch7x7dbl_1.bn : BatchNorm2d\n",
            "Mixed_6e.branch7x7dbl_2 : BasicConv2d\n",
            "Mixed_6e.branch7x7dbl_2.conv : Conv2d\n",
            "Mixed_6e.branch7x7dbl_2.bn : BatchNorm2d\n",
            "Mixed_6e.branch7x7dbl_3 : BasicConv2d\n",
            "Mixed_6e.branch7x7dbl_3.conv : Conv2d\n",
            "Mixed_6e.branch7x7dbl_3.bn : BatchNorm2d\n",
            "Mixed_6e.branch7x7dbl_4 : BasicConv2d\n",
            "Mixed_6e.branch7x7dbl_4.conv : Conv2d\n",
            "Mixed_6e.branch7x7dbl_4.bn : BatchNorm2d\n",
            "Mixed_6e.branch7x7dbl_5 : BasicConv2d\n",
            "Mixed_6e.branch7x7dbl_5.conv : Conv2d\n",
            "Mixed_6e.branch7x7dbl_5.bn : BatchNorm2d\n",
            "Mixed_6e.branch_pool : BasicConv2d\n",
            "Mixed_6e.branch_pool.conv : Conv2d\n",
            "Mixed_6e.branch_pool.bn : BatchNorm2d\n",
            "AuxLogits : InceptionAux\n",
            "AuxLogits.conv0 : BasicConv2d\n",
            "AuxLogits.conv0.conv : Conv2d\n",
            "AuxLogits.conv0.bn : BatchNorm2d\n",
            "AuxLogits.conv1 : BasicConv2d\n",
            "AuxLogits.conv1.conv : Conv2d\n",
            "AuxLogits.conv1.bn : BatchNorm2d\n",
            "AuxLogits.fc : Linear\n",
            "Mixed_7a : InceptionD\n",
            "Mixed_7a.branch3x3_1 : BasicConv2d\n",
            "Mixed_7a.branch3x3_1.conv : Conv2d\n",
            "Mixed_7a.branch3x3_1.bn : BatchNorm2d\n",
            "Mixed_7a.branch3x3_2 : BasicConv2d\n",
            "Mixed_7a.branch3x3_2.conv : Conv2d\n",
            "Mixed_7a.branch3x3_2.bn : BatchNorm2d\n",
            "Mixed_7a.branch7x7x3_1 : BasicConv2d\n",
            "Mixed_7a.branch7x7x3_1.conv : Conv2d\n",
            "Mixed_7a.branch7x7x3_1.bn : BatchNorm2d\n",
            "Mixed_7a.branch7x7x3_2 : BasicConv2d\n",
            "Mixed_7a.branch7x7x3_2.conv : Conv2d\n",
            "Mixed_7a.branch7x7x3_2.bn : BatchNorm2d\n",
            "Mixed_7a.branch7x7x3_3 : BasicConv2d\n",
            "Mixed_7a.branch7x7x3_3.conv : Conv2d\n",
            "Mixed_7a.branch7x7x3_3.bn : BatchNorm2d\n",
            "Mixed_7a.branch7x7x3_4 : BasicConv2d\n",
            "Mixed_7a.branch7x7x3_4.conv : Conv2d\n",
            "Mixed_7a.branch7x7x3_4.bn : BatchNorm2d\n",
            "Mixed_7b : InceptionE\n",
            "Mixed_7b.branch1x1 : BasicConv2d\n",
            "Mixed_7b.branch1x1.conv : Conv2d\n",
            "Mixed_7b.branch1x1.bn : BatchNorm2d\n",
            "Mixed_7b.branch3x3_1 : BasicConv2d\n",
            "Mixed_7b.branch3x3_1.conv : Conv2d\n",
            "Mixed_7b.branch3x3_1.bn : BatchNorm2d\n",
            "Mixed_7b.branch3x3_2a : BasicConv2d\n",
            "Mixed_7b.branch3x3_2a.conv : Conv2d\n",
            "Mixed_7b.branch3x3_2a.bn : BatchNorm2d\n",
            "Mixed_7b.branch3x3_2b : BasicConv2d\n",
            "Mixed_7b.branch3x3_2b.conv : Conv2d\n",
            "Mixed_7b.branch3x3_2b.bn : BatchNorm2d\n",
            "Mixed_7b.branch3x3dbl_1 : BasicConv2d\n",
            "Mixed_7b.branch3x3dbl_1.conv : Conv2d\n",
            "Mixed_7b.branch3x3dbl_1.bn : BatchNorm2d\n",
            "Mixed_7b.branch3x3dbl_2 : BasicConv2d\n",
            "Mixed_7b.branch3x3dbl_2.conv : Conv2d\n",
            "Mixed_7b.branch3x3dbl_2.bn : BatchNorm2d\n",
            "Mixed_7b.branch3x3dbl_3a : BasicConv2d\n",
            "Mixed_7b.branch3x3dbl_3a.conv : Conv2d\n",
            "Mixed_7b.branch3x3dbl_3a.bn : BatchNorm2d\n",
            "Mixed_7b.branch3x3dbl_3b : BasicConv2d\n",
            "Mixed_7b.branch3x3dbl_3b.conv : Conv2d\n",
            "Mixed_7b.branch3x3dbl_3b.bn : BatchNorm2d\n",
            "Mixed_7b.branch_pool : BasicConv2d\n",
            "Mixed_7b.branch_pool.conv : Conv2d\n",
            "Mixed_7b.branch_pool.bn : BatchNorm2d\n",
            "Mixed_7c : InceptionE\n",
            "Mixed_7c.branch1x1 : BasicConv2d\n",
            "Mixed_7c.branch1x1.conv : Conv2d\n",
            "Mixed_7c.branch1x1.bn : BatchNorm2d\n",
            "Mixed_7c.branch3x3_1 : BasicConv2d\n",
            "Mixed_7c.branch3x3_1.conv : Conv2d\n",
            "Mixed_7c.branch3x3_1.bn : BatchNorm2d\n",
            "Mixed_7c.branch3x3_2a : BasicConv2d\n",
            "Mixed_7c.branch3x3_2a.conv : Conv2d\n",
            "Mixed_7c.branch3x3_2a.bn : BatchNorm2d\n",
            "Mixed_7c.branch3x3_2b : BasicConv2d\n",
            "Mixed_7c.branch3x3_2b.conv : Conv2d\n",
            "Mixed_7c.branch3x3_2b.bn : BatchNorm2d\n",
            "Mixed_7c.branch3x3dbl_1 : BasicConv2d\n",
            "Mixed_7c.branch3x3dbl_1.conv : Conv2d\n",
            "Mixed_7c.branch3x3dbl_1.bn : BatchNorm2d\n",
            "Mixed_7c.branch3x3dbl_2 : BasicConv2d\n",
            "Mixed_7c.branch3x3dbl_2.conv : Conv2d\n",
            "Mixed_7c.branch3x3dbl_2.bn : BatchNorm2d\n",
            "Mixed_7c.branch3x3dbl_3a : BasicConv2d\n",
            "Mixed_7c.branch3x3dbl_3a.conv : Conv2d\n",
            "Mixed_7c.branch3x3dbl_3a.bn : BatchNorm2d\n",
            "Mixed_7c.branch3x3dbl_3b : BasicConv2d\n",
            "Mixed_7c.branch3x3dbl_3b.conv : Conv2d\n",
            "Mixed_7c.branch3x3dbl_3b.bn : BatchNorm2d\n",
            "Mixed_7c.branch_pool : BasicConv2d\n",
            "Mixed_7c.branch_pool.conv : Conv2d\n",
            "Mixed_7c.branch_pool.bn : BatchNorm2d\n",
            "avgpool : AdaptiveAvgPool2d\n",
            "dropout : Dropout\n",
            "fc : Linear\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 149, 149]             864\n",
            "       BatchNorm2d-2         [-1, 32, 149, 149]              64\n",
            "       BasicConv2d-3         [-1, 32, 149, 149]               0\n",
            "            Conv2d-4         [-1, 32, 147, 147]           9,216\n",
            "       BatchNorm2d-5         [-1, 32, 147, 147]              64\n",
            "       BasicConv2d-6         [-1, 32, 147, 147]               0\n",
            "            Conv2d-7         [-1, 64, 147, 147]          18,432\n",
            "       BatchNorm2d-8         [-1, 64, 147, 147]             128\n",
            "       BasicConv2d-9         [-1, 64, 147, 147]               0\n",
            "        MaxPool2d-10           [-1, 64, 73, 73]               0\n",
            "           Conv2d-11           [-1, 80, 73, 73]           5,120\n",
            "      BatchNorm2d-12           [-1, 80, 73, 73]             160\n",
            "      BasicConv2d-13           [-1, 80, 73, 73]               0\n",
            "           Conv2d-14          [-1, 192, 71, 71]         138,240\n",
            "      BatchNorm2d-15          [-1, 192, 71, 71]             384\n",
            "      BasicConv2d-16          [-1, 192, 71, 71]               0\n",
            "        MaxPool2d-17          [-1, 192, 35, 35]               0\n",
            "           Conv2d-18           [-1, 64, 35, 35]          12,288\n",
            "      BatchNorm2d-19           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-20           [-1, 64, 35, 35]               0\n",
            "           Conv2d-21           [-1, 48, 35, 35]           9,216\n",
            "      BatchNorm2d-22           [-1, 48, 35, 35]              96\n",
            "      BasicConv2d-23           [-1, 48, 35, 35]               0\n",
            "           Conv2d-24           [-1, 64, 35, 35]          76,800\n",
            "      BatchNorm2d-25           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-26           [-1, 64, 35, 35]               0\n",
            "           Conv2d-27           [-1, 64, 35, 35]          12,288\n",
            "      BatchNorm2d-28           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-29           [-1, 64, 35, 35]               0\n",
            "           Conv2d-30           [-1, 96, 35, 35]          55,296\n",
            "      BatchNorm2d-31           [-1, 96, 35, 35]             192\n",
            "      BasicConv2d-32           [-1, 96, 35, 35]               0\n",
            "           Conv2d-33           [-1, 96, 35, 35]          82,944\n",
            "      BatchNorm2d-34           [-1, 96, 35, 35]             192\n",
            "      BasicConv2d-35           [-1, 96, 35, 35]               0\n",
            "           Conv2d-36           [-1, 32, 35, 35]           6,144\n",
            "      BatchNorm2d-37           [-1, 32, 35, 35]              64\n",
            "      BasicConv2d-38           [-1, 32, 35, 35]               0\n",
            "       InceptionA-39          [-1, 256, 35, 35]               0\n",
            "           Conv2d-40           [-1, 64, 35, 35]          16,384\n",
            "      BatchNorm2d-41           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-42           [-1, 64, 35, 35]               0\n",
            "           Conv2d-43           [-1, 48, 35, 35]          12,288\n",
            "      BatchNorm2d-44           [-1, 48, 35, 35]              96\n",
            "      BasicConv2d-45           [-1, 48, 35, 35]               0\n",
            "           Conv2d-46           [-1, 64, 35, 35]          76,800\n",
            "      BatchNorm2d-47           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-48           [-1, 64, 35, 35]               0\n",
            "           Conv2d-49           [-1, 64, 35, 35]          16,384\n",
            "      BatchNorm2d-50           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-51           [-1, 64, 35, 35]               0\n",
            "           Conv2d-52           [-1, 96, 35, 35]          55,296\n",
            "      BatchNorm2d-53           [-1, 96, 35, 35]             192\n",
            "      BasicConv2d-54           [-1, 96, 35, 35]               0\n",
            "           Conv2d-55           [-1, 96, 35, 35]          82,944\n",
            "      BatchNorm2d-56           [-1, 96, 35, 35]             192\n",
            "      BasicConv2d-57           [-1, 96, 35, 35]               0\n",
            "           Conv2d-58           [-1, 64, 35, 35]          16,384\n",
            "      BatchNorm2d-59           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-60           [-1, 64, 35, 35]               0\n",
            "       InceptionA-61          [-1, 288, 35, 35]               0\n",
            "           Conv2d-62           [-1, 64, 35, 35]          18,432\n",
            "      BatchNorm2d-63           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-64           [-1, 64, 35, 35]               0\n",
            "           Conv2d-65           [-1, 48, 35, 35]          13,824\n",
            "      BatchNorm2d-66           [-1, 48, 35, 35]              96\n",
            "      BasicConv2d-67           [-1, 48, 35, 35]               0\n",
            "           Conv2d-68           [-1, 64, 35, 35]          76,800\n",
            "      BatchNorm2d-69           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-70           [-1, 64, 35, 35]               0\n",
            "           Conv2d-71           [-1, 64, 35, 35]          18,432\n",
            "      BatchNorm2d-72           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-73           [-1, 64, 35, 35]               0\n",
            "           Conv2d-74           [-1, 96, 35, 35]          55,296\n",
            "      BatchNorm2d-75           [-1, 96, 35, 35]             192\n",
            "      BasicConv2d-76           [-1, 96, 35, 35]               0\n",
            "           Conv2d-77           [-1, 96, 35, 35]          82,944\n",
            "      BatchNorm2d-78           [-1, 96, 35, 35]             192\n",
            "      BasicConv2d-79           [-1, 96, 35, 35]               0\n",
            "           Conv2d-80           [-1, 64, 35, 35]          18,432\n",
            "      BatchNorm2d-81           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-82           [-1, 64, 35, 35]               0\n",
            "       InceptionA-83          [-1, 288, 35, 35]               0\n",
            "           Conv2d-84          [-1, 384, 17, 17]         995,328\n",
            "      BatchNorm2d-85          [-1, 384, 17, 17]             768\n",
            "      BasicConv2d-86          [-1, 384, 17, 17]               0\n",
            "           Conv2d-87           [-1, 64, 35, 35]          18,432\n",
            "      BatchNorm2d-88           [-1, 64, 35, 35]             128\n",
            "      BasicConv2d-89           [-1, 64, 35, 35]               0\n",
            "           Conv2d-90           [-1, 96, 35, 35]          55,296\n",
            "      BatchNorm2d-91           [-1, 96, 35, 35]             192\n",
            "      BasicConv2d-92           [-1, 96, 35, 35]               0\n",
            "           Conv2d-93           [-1, 96, 17, 17]          82,944\n",
            "      BatchNorm2d-94           [-1, 96, 17, 17]             192\n",
            "      BasicConv2d-95           [-1, 96, 17, 17]               0\n",
            "       InceptionB-96          [-1, 768, 17, 17]               0\n",
            "           Conv2d-97          [-1, 192, 17, 17]         147,456\n",
            "      BatchNorm2d-98          [-1, 192, 17, 17]             384\n",
            "      BasicConv2d-99          [-1, 192, 17, 17]               0\n",
            "          Conv2d-100          [-1, 128, 17, 17]          98,304\n",
            "     BatchNorm2d-101          [-1, 128, 17, 17]             256\n",
            "     BasicConv2d-102          [-1, 128, 17, 17]               0\n",
            "          Conv2d-103          [-1, 128, 17, 17]         114,688\n",
            "     BatchNorm2d-104          [-1, 128, 17, 17]             256\n",
            "     BasicConv2d-105          [-1, 128, 17, 17]               0\n",
            "          Conv2d-106          [-1, 192, 17, 17]         172,032\n",
            "     BatchNorm2d-107          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-108          [-1, 192, 17, 17]               0\n",
            "          Conv2d-109          [-1, 128, 17, 17]          98,304\n",
            "     BatchNorm2d-110          [-1, 128, 17, 17]             256\n",
            "     BasicConv2d-111          [-1, 128, 17, 17]               0\n",
            "          Conv2d-112          [-1, 128, 17, 17]         114,688\n",
            "     BatchNorm2d-113          [-1, 128, 17, 17]             256\n",
            "     BasicConv2d-114          [-1, 128, 17, 17]               0\n",
            "          Conv2d-115          [-1, 128, 17, 17]         114,688\n",
            "     BatchNorm2d-116          [-1, 128, 17, 17]             256\n",
            "     BasicConv2d-117          [-1, 128, 17, 17]               0\n",
            "          Conv2d-118          [-1, 128, 17, 17]         114,688\n",
            "     BatchNorm2d-119          [-1, 128, 17, 17]             256\n",
            "     BasicConv2d-120          [-1, 128, 17, 17]               0\n",
            "          Conv2d-121          [-1, 192, 17, 17]         172,032\n",
            "     BatchNorm2d-122          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-123          [-1, 192, 17, 17]               0\n",
            "          Conv2d-124          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-125          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-126          [-1, 192, 17, 17]               0\n",
            "      InceptionC-127          [-1, 768, 17, 17]               0\n",
            "          Conv2d-128          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-129          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-130          [-1, 192, 17, 17]               0\n",
            "          Conv2d-131          [-1, 160, 17, 17]         122,880\n",
            "     BatchNorm2d-132          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-133          [-1, 160, 17, 17]               0\n",
            "          Conv2d-134          [-1, 160, 17, 17]         179,200\n",
            "     BatchNorm2d-135          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-136          [-1, 160, 17, 17]               0\n",
            "          Conv2d-137          [-1, 192, 17, 17]         215,040\n",
            "     BatchNorm2d-138          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-139          [-1, 192, 17, 17]               0\n",
            "          Conv2d-140          [-1, 160, 17, 17]         122,880\n",
            "     BatchNorm2d-141          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-142          [-1, 160, 17, 17]               0\n",
            "          Conv2d-143          [-1, 160, 17, 17]         179,200\n",
            "     BatchNorm2d-144          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-145          [-1, 160, 17, 17]               0\n",
            "          Conv2d-146          [-1, 160, 17, 17]         179,200\n",
            "     BatchNorm2d-147          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-148          [-1, 160, 17, 17]               0\n",
            "          Conv2d-149          [-1, 160, 17, 17]         179,200\n",
            "     BatchNorm2d-150          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-151          [-1, 160, 17, 17]               0\n",
            "          Conv2d-152          [-1, 192, 17, 17]         215,040\n",
            "     BatchNorm2d-153          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-154          [-1, 192, 17, 17]               0\n",
            "          Conv2d-155          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-156          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-157          [-1, 192, 17, 17]               0\n",
            "      InceptionC-158          [-1, 768, 17, 17]               0\n",
            "          Conv2d-159          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-160          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-161          [-1, 192, 17, 17]               0\n",
            "          Conv2d-162          [-1, 160, 17, 17]         122,880\n",
            "     BatchNorm2d-163          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-164          [-1, 160, 17, 17]               0\n",
            "          Conv2d-165          [-1, 160, 17, 17]         179,200\n",
            "     BatchNorm2d-166          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-167          [-1, 160, 17, 17]               0\n",
            "          Conv2d-168          [-1, 192, 17, 17]         215,040\n",
            "     BatchNorm2d-169          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-170          [-1, 192, 17, 17]               0\n",
            "          Conv2d-171          [-1, 160, 17, 17]         122,880\n",
            "     BatchNorm2d-172          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-173          [-1, 160, 17, 17]               0\n",
            "          Conv2d-174          [-1, 160, 17, 17]         179,200\n",
            "     BatchNorm2d-175          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-176          [-1, 160, 17, 17]               0\n",
            "          Conv2d-177          [-1, 160, 17, 17]         179,200\n",
            "     BatchNorm2d-178          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-179          [-1, 160, 17, 17]               0\n",
            "          Conv2d-180          [-1, 160, 17, 17]         179,200\n",
            "     BatchNorm2d-181          [-1, 160, 17, 17]             320\n",
            "     BasicConv2d-182          [-1, 160, 17, 17]               0\n",
            "          Conv2d-183          [-1, 192, 17, 17]         215,040\n",
            "     BatchNorm2d-184          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-185          [-1, 192, 17, 17]               0\n",
            "          Conv2d-186          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-187          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-188          [-1, 192, 17, 17]               0\n",
            "      InceptionC-189          [-1, 768, 17, 17]               0\n",
            "          Conv2d-190          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-191          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-192          [-1, 192, 17, 17]               0\n",
            "          Conv2d-193          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-194          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-195          [-1, 192, 17, 17]               0\n",
            "          Conv2d-196          [-1, 192, 17, 17]         258,048\n",
            "     BatchNorm2d-197          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-198          [-1, 192, 17, 17]               0\n",
            "          Conv2d-199          [-1, 192, 17, 17]         258,048\n",
            "     BatchNorm2d-200          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-201          [-1, 192, 17, 17]               0\n",
            "          Conv2d-202          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-203          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-204          [-1, 192, 17, 17]               0\n",
            "          Conv2d-205          [-1, 192, 17, 17]         258,048\n",
            "     BatchNorm2d-206          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-207          [-1, 192, 17, 17]               0\n",
            "          Conv2d-208          [-1, 192, 17, 17]         258,048\n",
            "     BatchNorm2d-209          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-210          [-1, 192, 17, 17]               0\n",
            "          Conv2d-211          [-1, 192, 17, 17]         258,048\n",
            "     BatchNorm2d-212          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-213          [-1, 192, 17, 17]               0\n",
            "          Conv2d-214          [-1, 192, 17, 17]         258,048\n",
            "     BatchNorm2d-215          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-216          [-1, 192, 17, 17]               0\n",
            "          Conv2d-217          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-218          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-219          [-1, 192, 17, 17]               0\n",
            "      InceptionC-220          [-1, 768, 17, 17]               0\n",
            "          Conv2d-221            [-1, 128, 5, 5]          98,304\n",
            "     BatchNorm2d-222            [-1, 128, 5, 5]             256\n",
            "     BasicConv2d-223            [-1, 128, 5, 5]               0\n",
            "          Conv2d-224            [-1, 768, 1, 1]       2,457,600\n",
            "     BatchNorm2d-225            [-1, 768, 1, 1]           1,536\n",
            "     BasicConv2d-226            [-1, 768, 1, 1]               0\n",
            "          Linear-227                 [-1, 1000]         769,000\n",
            "    InceptionAux-228                 [-1, 1000]               0\n",
            "          Conv2d-229          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-230          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-231          [-1, 192, 17, 17]               0\n",
            "          Conv2d-232            [-1, 320, 8, 8]         552,960\n",
            "     BatchNorm2d-233            [-1, 320, 8, 8]             640\n",
            "     BasicConv2d-234            [-1, 320, 8, 8]               0\n",
            "          Conv2d-235          [-1, 192, 17, 17]         147,456\n",
            "     BatchNorm2d-236          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-237          [-1, 192, 17, 17]               0\n",
            "          Conv2d-238          [-1, 192, 17, 17]         258,048\n",
            "     BatchNorm2d-239          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-240          [-1, 192, 17, 17]               0\n",
            "          Conv2d-241          [-1, 192, 17, 17]         258,048\n",
            "     BatchNorm2d-242          [-1, 192, 17, 17]             384\n",
            "     BasicConv2d-243          [-1, 192, 17, 17]               0\n",
            "          Conv2d-244            [-1, 192, 8, 8]         331,776\n",
            "     BatchNorm2d-245            [-1, 192, 8, 8]             384\n",
            "     BasicConv2d-246            [-1, 192, 8, 8]               0\n",
            "      InceptionD-247           [-1, 1280, 8, 8]               0\n",
            "          Conv2d-248            [-1, 320, 8, 8]         409,600\n",
            "     BatchNorm2d-249            [-1, 320, 8, 8]             640\n",
            "     BasicConv2d-250            [-1, 320, 8, 8]               0\n",
            "          Conv2d-251            [-1, 384, 8, 8]         491,520\n",
            "     BatchNorm2d-252            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-253            [-1, 384, 8, 8]               0\n",
            "          Conv2d-254            [-1, 384, 8, 8]         442,368\n",
            "     BatchNorm2d-255            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-256            [-1, 384, 8, 8]               0\n",
            "          Conv2d-257            [-1, 384, 8, 8]         442,368\n",
            "     BatchNorm2d-258            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-259            [-1, 384, 8, 8]               0\n",
            "          Conv2d-260            [-1, 448, 8, 8]         573,440\n",
            "     BatchNorm2d-261            [-1, 448, 8, 8]             896\n",
            "     BasicConv2d-262            [-1, 448, 8, 8]               0\n",
            "          Conv2d-263            [-1, 384, 8, 8]       1,548,288\n",
            "     BatchNorm2d-264            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-265            [-1, 384, 8, 8]               0\n",
            "          Conv2d-266            [-1, 384, 8, 8]         442,368\n",
            "     BatchNorm2d-267            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-268            [-1, 384, 8, 8]               0\n",
            "          Conv2d-269            [-1, 384, 8, 8]         442,368\n",
            "     BatchNorm2d-270            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-271            [-1, 384, 8, 8]               0\n",
            "          Conv2d-272            [-1, 192, 8, 8]         245,760\n",
            "     BatchNorm2d-273            [-1, 192, 8, 8]             384\n",
            "     BasicConv2d-274            [-1, 192, 8, 8]               0\n",
            "      InceptionE-275           [-1, 2048, 8, 8]               0\n",
            "          Conv2d-276            [-1, 320, 8, 8]         655,360\n",
            "     BatchNorm2d-277            [-1, 320, 8, 8]             640\n",
            "     BasicConv2d-278            [-1, 320, 8, 8]               0\n",
            "          Conv2d-279            [-1, 384, 8, 8]         786,432\n",
            "     BatchNorm2d-280            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-281            [-1, 384, 8, 8]               0\n",
            "          Conv2d-282            [-1, 384, 8, 8]         442,368\n",
            "     BatchNorm2d-283            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-284            [-1, 384, 8, 8]               0\n",
            "          Conv2d-285            [-1, 384, 8, 8]         442,368\n",
            "     BatchNorm2d-286            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-287            [-1, 384, 8, 8]               0\n",
            "          Conv2d-288            [-1, 448, 8, 8]         917,504\n",
            "     BatchNorm2d-289            [-1, 448, 8, 8]             896\n",
            "     BasicConv2d-290            [-1, 448, 8, 8]               0\n",
            "          Conv2d-291            [-1, 384, 8, 8]       1,548,288\n",
            "     BatchNorm2d-292            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-293            [-1, 384, 8, 8]               0\n",
            "          Conv2d-294            [-1, 384, 8, 8]         442,368\n",
            "     BatchNorm2d-295            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-296            [-1, 384, 8, 8]               0\n",
            "          Conv2d-297            [-1, 384, 8, 8]         442,368\n",
            "     BatchNorm2d-298            [-1, 384, 8, 8]             768\n",
            "     BasicConv2d-299            [-1, 384, 8, 8]               0\n",
            "          Conv2d-300            [-1, 192, 8, 8]         393,216\n",
            "     BatchNorm2d-301            [-1, 192, 8, 8]             384\n",
            "     BasicConv2d-302            [-1, 192, 8, 8]               0\n",
            "      InceptionE-303           [-1, 2048, 8, 8]               0\n",
            "AdaptiveAvgPool2d-304           [-1, 2048, 1, 1]               0\n",
            "         Dropout-305           [-1, 2048, 1, 1]               0\n",
            "          Linear-306                 [-1, 1000]       2,049,000\n",
            "================================================================\n",
            "Total params: 27,161,264\n",
            "Trainable params: 27,161,264\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.02\n",
            "Forward/backward pass size (MB): 228.66\n",
            "Params size (MB): 103.61\n",
            "Estimated Total Size (MB): 333.29\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.optim import RMSprop\n",
        "\n",
        "# Load the pre-trained Inception V3 model\n",
        "pre_trained_model = models.inception_v3(pretrained=True, aux_logits=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "pre_trained_model.to(device)\n",
        "\n",
        "def print_model_summary(model):\n",
        "    for name, module in model.named_modules():\n",
        "        print(f\"{name} : {module.__class__.__name__}\")\n",
        "\n",
        "# Example of how to use the function with your pre-trained model\n",
        "print_model_summary(pre_trained_model)\n",
        "\n",
        "from torchsummary import summary\n",
        "summary(pre_trained_model, input_size=(3, 299, 299))  # (Channels, Height, Width)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofCmZ66EQCAc"
      },
      "outputs": [],
      "source": [
        "# Freeze all layers up to and including the 'Mixed_7c'\n",
        "for name, parameter in pre_trained_model.named_parameters():\n",
        "    parameter.requires_grad = False\n",
        "    if 'Mixed_7c' in name:\n",
        "        break\n",
        "\n",
        "# Modify the existing fully connected layer\n",
        "num_ftrs = pre_trained_model.fc.in_features\n",
        "pre_trained_model.fc = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 1024),  # New fully connected layer with 1024 outputs\n",
        "    nn.ReLU(),                # Activation layer\n",
        "    # nn.DropOut(0.5),\n",
        "    nn.Linear(1024, 3)         # Final layer for binary classification\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, train_loader, num_epochs=10):\n",
        "    model.train()  # Set the model to training mode\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            # Handle multiple outputs for training with auxiliary logits\n",
        "            if isinstance(outputs, tuple):\n",
        "                output, aux_output = outputs\n",
        "                loss1 = criterion(output, labels)\n",
        "                loss2 = criterion(aux_output, labels)\n",
        "                loss = loss1 + 0.4 * loss2  # Scale the auxiliary loss as is standard for Inception\n",
        "            else:\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            _, preds = torch.max(output, 1)  # Ensure you use the main output for accuracy calculation\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels).item()\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_acc = running_corrects / len(train_loader.dataset)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "jMiFLJiBQKpQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3 - Loss: 3.8386, Acc: 0.9528\n",
            "Epoch 2/3 - Loss: 3.2533, Acc: 1.0000\n",
            "Epoch 3/3 - Loss: 3.2535, Acc: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# Only optimize parameters that are set to be trainable\n",
        "optimizer = RMSprop(filter(lambda p: p.requires_grad, pre_trained_model.parameters()), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model\n",
        "train_model(pre_trained_model, criterion, optimizer, train_loader, num_epochs=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkduW3KZaZYu"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "def load_image(image_path, transform):\n",
        "    # Load image\n",
        "    image = Image.open(image_path).convert('RGB')  # Convert to RGB just in case it's not\n",
        "    # Apply transformations\n",
        "    image = transform(image)\n",
        "    # Add batch dimension, as the model expects batches\n",
        "    image = image.unsqueeze(0)\n",
        "    return image\n",
        "\n",
        "# Prediction function\n",
        "def predict(image_path, model, device, transform):\n",
        "    model.eval()\n",
        "    image = load_image(image_path, transform)\n",
        "    image = image.to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "        print(output)\n",
        "        prediction = torch.max(output, 1)\n",
        "        print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GiZLEmMad4b"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "for img in uploaded.keys():\n",
        "  predict(img, pre_trained_model, device, transform)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
